# 3.3 VIRTUAL MEMORY

Mientras que los registro base y limite pueden ser usados para crear la abstracción de direcciones de memoria, hay otro problema que debe ser resuelto: gestión del bloatware. Mientras que los tamaños de memoria incrementan rápidamente, los tamaños del software incrementan mucho más rápido. En 1980, muchas universidades ejecutaban un sistema timesharing con docenas de usuarios(masomenos satisfechos) que funcionaban simultáneamente en una VAX de 4 MB. Ahora Microsoft recomienda tener al menos 2GB para Windows 8 de 64 bits. La tendencia hacia el multimedia exige aún más memoria. 

En consecuencia a este desarrollo, existe una necesidad de ejecutar programas que son muy grandes para caber en memoria, además un sistema debe soportar multiples programas ejecutándose simultáneamente, cada uno de los cuales cabe en memoria, pero juntos exceden colectivamente la memoria. El intercambio no es una opción atractiva, ya que un disco SATA típico tiene una velocidad de transferencia máxima de varios cientos de MB/s, lo que significa que se tarda segundos en intercambiar un programa de 1GB y lo mismo en intercambiar otro programa de 1GB.

El problema con los problemas más grandes que la memoria existen desde los inicios de las computadoras, aunque en ámbitos limitados como la ciencia y la ingeniería(simular la creación del universo o incluso simular un nuevo avión requiere mucha memoria). Una solución adoptada en los años 60 fue dividir los programas en pequeños trozos, llamados **overlay**. Cuando se iniciaba un programa, lo único que se cargaba en memoria era el gestor de overlay, que inmediatamente cargaba y ejecutaba la superposición 0. Cuando terminaba, le decia al overlay manager que cargara el overlay 1, ya sea encima de la posición 0 en memoria (si habia espacio para ella) o encima del overlay 0(si no habia espacio). Algunos sistemas de overlay eran muy complejos y permitian varios overlay en memoria al mismo tiempo.

Los overlays se guardaban en el disco y el gestor de overlay las intercambiaba dentro y fuera de la memoria.

Aunque el sistema operativo se encargaba de introducir y extraer los overlays, el programador tenia que dividir el programa en partes manualmente. Dividir programas grandes en partes pequeñas y modulares llevaba mucho tiempo, era aburrido y propenso a errores. Pocos programadores eran buenos en esto. No pasó mucho tiempo antes de que a alguien se le ocurriera la manera de delegar todo el trabajo a la computadora.

El método ideado(Fotherigam, 1961) se conoce como **virtual memory**. La idea básica bajo la memoria virtual es que cada programa tenga su propio espacios de direcciones, el cual se divide en trozos llamados páginas. Cada página es un rango continuo de direcciones. Estas páginas se mapean en la memoria física, pero no todas las páginas tienen que estar en la memoria física al mismo tiempo para ejecutar el programa. Cuando un programa hace referencia a una parte de su espacio de memoria que está en la dirección física, el hardware realiza el mapeo necesario. Cuando el programa hace referencia a una parte de su espacio de memoria que no está en la memoria física, se avisa al sistema operativo para que busque la parte que falta y vuelva a ejecutar la instrucción que falló.

En cierto sentido, la memoria virtual es una generalización de la idea de los registros base y límite. El 8088 tenía registros base separados(pero no registros límite)para texto y datos. Con la memoria virtual en lugar de tener una reubicación separada sólo para los segmentos de texto y datos, todo el espacio de direcciones puede ser mapeado en la memoria física en unidades bastante pequeñas. Más adelante veremos cómo se implementa la memoria virtual. La memoria virtual funciona perfectamente en un sistema multiprogramación, con fragmentos de muchos programas en memoria a la vez. Mientras un programa está esperando a que se lean partes de sí mismo, la CPU puede ser entregada a otro proceso.

## 3.3.1 Paging

La mayoría de los sistemas de memoria virtual utilizan una técnica llamada paginación, que describiremos a continuación. En cualquier ordenador, los programas hacen referencia a un conjunto de direcciones de memoria. Cuando un programa ejecuta una instrucción como:

``` assembler
    MOV REG, 1000
```

lo hace para copiar el contenido de la dirección de memoria 1000 a REG (o viceversa, según el ordenador). Las direcciones pueden generarse utilizando indexación, registros base, registros de segmento y otras formas.



Estas direcciones generadas por el prograsma se llaman **virtual addreses** y forman el  **virtual address space**. En computadoras sin memoria virtual, la dirección virtual es puesta directamente el bus de direcciones y hace que se lea y escriba la palabra de memoria física con la misma dirección.

Cuando se usa memoria virtual, las direcciones virtuales no van directamente al bus de memoria. En vez de ello, ellos van al **MMU(Memory Management Unit)** que mapea las direcciones virtuales en direciones físicas como se ve en la figura 3-8.

![figure3-8](https://github.com/gabo52/SistemasOperativos/blob/main/figures/Chapter3/figure3-8.png?raw=true)

Un ejemplo bastante simple de como se mapea se ve en la figura 3-9. En este ejemplo, tenemos una computadora que genera 16 bits de direcciones desde 0 hasta 64K-1. Estas son direcciones virtuales. Esta computadora, de todos modos tiene solo 32KB de memoria física. Por lo tanto, aunque se pueden escribir programas de 64 KB, no se pueden cargar en memoria en su totalidad y ejecutarse. Sin embargo, en el disco debe haber una copia completa de la imagen central del programa, de hasta 64KB, para que puedan introducirse piezas cuando sea necesario.

El espacio de direcciones virtuales se compone de unidades de tamaño fijo denominadas páginas. Las unidades correspondientes en la memoria física se llaman **page frames**. Las páginas y los marcos de página suelen tener el mismo tamaño. En este ejemplo son 4KB, pero en sistemas reales se han utilizado tamaños de página desde 512 bytes hasta 1 GB. Con 64KB de espacio de direcciones virtuales y 32KB de memoria física, obtenemos 16 páginas virtuales y 8 marcos de página. Las transferencias entre RAM y disco se realizan siempre en páginas enteras. Muchos procesadores soportan múltiples tamaños de página que pueden mezclarse y combinarse como el sistema operativo considere oportuno. Por ejemplo, la arquitectura x86-64 admite páginas de 4KB, 2MB y 1GB, por lo que podríamos usar páginas de 4KB para las aplicaciones de usuario y una única página de 1GB para el núcleo. Más adelante veremos por qué aveces es mejor usar única página grande, en lugar de un gran número de páginas pequeñas.

La notación de la figura 3-9 es así. El rango marcado de 0K a 4K significa que la memoria ya sea virtual o física en esa página van de 0 a 4095. El rango 4K-8K hace referencia a que las direcciones de 4096 a 8191 y así. Cada página contiene exactamente 4096 direcciones comenzando desde un múltiplo de 4096 y terminando con un múltiplo de 4096 menos 1. Cuando el programa t°trata de acceder a la dirección 0, por ejemplo, usa la instrucción.

``` assembler
    MOV REG, 0
```
la dirección virtual 0 se envía al MMU. El MMU ve que la memoria virtual falla en la página 0 (0 a 4095), que según su mapeo, es el marco de página 2(8192 a 12287). Por lo tanto, transforma la dirección a la dirección 8192 y envía la dirección 8192 al bus. La memoria no sabe en absoluto acerca del MMU y solo ve una solicitud de lectura o escritura de la dirección 8192, que cumple. Así, la MMU ha mapeado efectivamente todas las direcciones virtuales entre 0 y 4095 en las direcciones físicas 8192 a 12287. 

De forma similar, la instrucción

``` assembler
    MOV REG, 8192
```

es efectivamente transformada en 

``` assembler
    MOV REG, 24576
```
dado que la dirección virtual 8192(en página virtual 2) es mapeada en 24756(en la página física, en el frame 6). Como tercer ejemplo, la dirección virtual 20500 está a 20 bytes del inicio de la página virtual 5(dirección virtual de 20480 a 24575) y mapea en la dirección física 12288 + 20 = 12308.


![figure3-9](https://github.com/gabo52/SistemasOperativos/blob/main/figures/Chapter3/figure3-9.png?raw=true)

Por sí mismo, la capacidad de asignar las 16 páginas virtuales a cualquiera de los 8 page frames configurando adecuadamente el mapa de la MMU no resuelve el problema de que el espacio de direcciones virtual sea mayor que la memoria física. Cómo solo tenemos 8 marcos de páginas físicas, sólo ocho de las páginas virtuales  de la figura 3-9 se pueden mapear en la memoria física. Las otras, mostradas como una cruz en la figura, no están mapeadas. En el hardware real, un **Present/absent bit** mantiene un registro de qué páginas se encuentran físicamente en memoria.

Qué pasa si el programa referencia una dirección de memoria no mapeada, por ejemplo, realizando la instrucción:

``` assembler
    MOV REG, 32780
```

La cual se encuentra 12 bytes del inicio de la página virtual 8 (comenzando en 32768)? El MMU notifica que la página no está mapeada(indicado por una X en la figura) y causa que la CPU llame al sistema operativo. Esta llamada es denominada **page fault**. El sistema operativo elige un page frame poco utilizado y escribe su contenido denuevo en el disco(si aún no está allí). A continuación recupera(también del disco) la página a la que acaba de hacer referencia en el marco de página que se acaba de liberar, cambia el mapa y reinicia la instrucción atrapada.

Por ejemplo, si el sistema operativo decidiera desalojar el marco de página 1, cargaría la página virtual 8 en la dirección física 4096 y realizaría 2 cambios en el mapa de la MMU. Primero, marcaría la entrada de la página virtual 1 como no mapeada, para atrapar cualquier acceso futuro a direcciones virtuales entre 4096 y 8191. Luego reemplazaría la X en la entrada de la página virtual 8 con un 1, de modo que cuando la instrucción atrapada sea reejecutada, mapeará la dirección virtual 32780 a la dirección física(4096 +12).

Ahora veamos dentro del MMU para ver cómo funciona y porqué hemos escogido usar un tamaño de página que es potencia de 2. En la figura 3-10 vemos un ejemplo de una dirección virtual, 8196 (0010000000000100 in binary), siendo mapeada usando el mapa MMU en la figura 3-9. La dirección virtual entrante de 16 bits es dividida en un número de páginas de 4 bits y un offset de 12 bits. Con 4 bits para el número de página, podemos 16 páginas, y con 12 bits para offset podemos tener 4096 bytes dentro de una página.

El número de páginas se usa como índice en la **page table**, lo que proporciona el número de page frames correspondiente a esa página virtual. Si el Present/absent bit es 0, se produce un trap al sistema operativo. Si el bit es 1, el número de marco de página encontrado en la tabla de páginas se copia en los 3 bits de orden superior del registro de salida, junto con el desplazamiento de 12 bits, que se copia sin modificar de la dirección entrante. Juntos forman una dirección física de 15 bits. A continuación, el registro de salida se coloca en el bus de memoria como dirección de memoria física.

## 3.3.2 Page Tables

En una implementación sencilla, el mapeo de direcciones virtuales en direcciones físicas puede resumirse esta manera: la dirección virtual se divide en un número de página virtual(bits de orden superior) y un  desplazamiento(bits de orden inferior). Por ejemplo, con una dirección de 16 bits y un tamaño de página de 4KB, los 4 bits superiores podrían especificar una de las 15 páginas virtuales y los 12 bits inferiores especificarían el desplazamiento de bytes (de 0 a 4095) dentro de la página seleccionada. Sin embargo también es posible una división con 3 o 5 u otro número de bits para la página. Diferente divisiones implican diferentes tamaños de página. 

El numero de la página virtual se utiliza como índica en la tabla de páginas para encontrar la entrada de esa página virtual. A partir de la entrada de la tabla de páginas, se encuentra el page frame(si existe). El número de pageframe se une al extremo superior del desplazamiento, sustituyendo al número de página virtual, para formar una dirección física que pueda enviarse a memoria.

Entonces, el propósito de la tabla de página es mapear páginas virtuales en los pageframes. Matematicamente hablando, la tabla de página es una función, con el número de página virtual como entrada y con el número físico de frame como resultado. Usando el resultado de esta función, el campo de página virtual en una dirección virtual se puede reemplazar por un campo de pageframe, formando una memoria física.

![figura3-10](https://github.com/gabo52/SistemasOperativos/blob/main/figures/Chapter3/figure3-10.png?raw=true)

En este capítulo, nos preocupamos acerca de la memoria virtual y no de la completa virtualización. En otras palabras, todavía no veremos las máquinas virtuales, esto lo veremos en el cap 7. donde cada máquina virtual necesita su propia memoria virtual, como resultado, la organización de tablas de página se vuelve más complicado(incluyendo tablas de páginas ocultados o anidadas y más). Incluso sin tales configuraciones, paginación y memoria virtual son bastante sofisticados, como veremos.

### Structure of a Page Table Entry

Vemos ahora los detalles de una entrada de una sola tabla de página.El diseño exacto de una tabla de página es muy dependiente de la máquina, pero el tipo de información que presenta es masomenos lo mismo de máquina a máquina. En la figura 3-11 presentamos una entrada de tabla de página de muestra. El tamaño varía de computadora a computadora, pero 32 bits es un tamaño común. El campo más importante es el *Page frame number*. Después de esto, el objetivo del mapeo de página es retornar este valor. Después de esto tenemos el *Present/absent* bit. Si el bit es 1, la entrada es válida y puede ser usada. Si es 0, la página virtual a la que pertenece la entrada, no se encuentra en memoria. Acceder a una entrada de tabla de página cuyo bit es 0 causa un fallo de página. 

![figura3-11](https://github.com/gabo52/SistemasOperativos/blob/main/figures/Chapter3/figure3-11.png?raw=true)

Los *Protection* bits indican qué tipos de acceso están permitidos. De la forma más simple, este bit contiene 1 bit, 0 para leer y escribir y 1 para solo lectura. Un arreglo más sofisticado tiene 3 bits, uno para permitir lectura, escritura y para ejecutar la página.

El *modified* y *referenced* bits mantienen un registro del uso de página. Cuando se escribe en una página, el hardware automáticamente setea el *modified* bit. Este bit es de valor cuando el sistema operativo decide reclamar un page frame. Si la página que contiene ha sido modificada(es decir, está "sucia"), debe volver a escribirse en el disco. Si no ha sido modificada(es decir, está "limpio"), simplemente puede abandonar, ya que la copia del disco es todavía válida. El bit aveces se llama **dirty bit**, ya que refleja el estado de página.

El *referenced* bit es seteado cada vez que se hace referencia a una página, ya sea por lectura o escritura. Este valor es usado por el sistema operativo para escoger una página para desalojarla cuando se produce un fallo de página. Las páginas que no se utilizan mucho son mucho mejores candidatas que las páginas que sí se utilizan, y este bit juega un papel importante en varios de los algoritmos de reemplazo de páginas que estudiaremos después en este capítulo.

Finalmente, el último bit permite deshabilitar el almacenamiento en caché para la página. Esta característica es importante para las páginas que se mapean a los registros de dispositivos en lugar de la memoria. Si el sistema operativo se encuentra en un bucle esperando algún dispositivo I/O para responder a algún comando que se acaba de realizar, es importante que el hardware siga buscando la palabra desde el dispositivo y no use una copia antigua almacenada en caché. Con este bit, el almacenamiento en caché puede ser apagado. Máquinas que tienen espacio de I/O separado y no usan mapeo de memoria I/O no necesitan este bit.

Notemos que la dirección del disco usada para manejar la página cuando no está en memoria no es parte de la tabla de página. La razón es simple. La tabla de página solo usa la información que el  hardware necesita para traducir una dirección virtual a una dirección física. La información que el sistema operativo necesita para manejar estos fallos de página se encuentran en las tablas del software en el sistema operativo. El hardware no los necesita.

Antes de entrar a más problemas de implementación, vale la pena señalar de nuevo que lo que hace fundamentalmente la memoria virtual es crear una nueva abstracción(el espacio de memoria) la cual es una abstracción de la memoria física, así como un proceso es una abstracción del procesador físico(CPU). La memoria virtual puede ser implementada dividiendo los espacios de dirección virtual en páginas, y mapeando cada una de ellas algún page frame o teniendóla(temporalmente) no mapeada. De este modo esta sección es básicamente sobre una abstracción creada por el sistema operativo y cómo se gestiona esa abstracción.

## 3.3.3 Speeding Up Paging

Acabamos de ver los conceptos básicos de memoria virtual y paginación. Ahora vamos a ver más a detalle las posibles implementaciones. En cualquier sistema de paginación se deben enfrentar 2 problemas.

1. El mapeo de una dirección virtual a una dirección física debe ser rápido.
2. Si el espacio de direcciones virtuales es grande, la tabla de página debe ser larga.
   
El primer punto es una consecuencia del hecho que el mapeo de virtual a físico debe ser realizado para cada referencia a memoria. Todas las instrucciones deben llegar finalmente a memoria y muchos de ellos también hacen referencia a operandos en la memoria. Consecuente, es necesario realizar múltiples references a la tabla de página por instrucción. Si una instrucción toma 1 nsec, la búsqueda de tabla de página debe realizar en menos de 0,2 ns para evitar que el mapeo se convierta en un cuello de botella importante.

El segundo punto se deriva del hecho de que todas las computadoras modernas usan direcciones virtuales de almenos 32 bits, siendo 64 bits un estándar para las computadoras de escritorio y laptops.Con un tamaño de página de 4KB, un espacio de direcciones de 32 bits, tiene un millón de páginas y los espacios de direcciones de 64 bits tienen más de lo que se desea contemplar. Con 1 millon de páginas en el espacio de direcciones virtuales, la tabla de página debe tener 1 millón de entradas. Y recordemos que cada proceso necesita su propia tabla de página(porque tiene su propio espacio de direcciones virtual).


La necesidad de un mapeo de páginas grande y rápido es una restricción de muy significativa en la forma en la que se construyen computadoras. El diseño más simple(al menos conceptualmente hablando) es tener una sola página que consta de una matriz de registros de hardware rápidos, con una entrada para cada página virtual, indexada por el número de página virtual, como se muestra en la figura 3-10. 

Cuando se inicia un proceso, el sistema operativo carga los registros con la tabla de página del proceso, tomada de una copia guardada en la memoria principal. Durante el proceso de ejecución, no se necesitan agregar más referencia de memoria a la página. La ventaja de este método es que es sencillo y no requeriere referencias a memoria durante el mapeo. Una desventaja es que resulta insoportablemente caro si la tabla de páginas es grande, simplemente no es práctico la mayoría de las veces. Otro motivo es que tener que cargar la tabla de páginas completa en cada switch acabaría con el rendimiento.

En el otro extremo, la tabla de página puede guardarse completamente en la memoria principal. Todo el harware que necesita entonces es un único registro que apunte al inicio de la tabla de páginas. Este diseño permite cambiar el mapa virtual a físico en un context switch cargando un registro. Por supuesto, tiene la desventaja de requerir una o más referencias de memoria para leer las entradas de la tabla de páginas durante la ejecución de cada instrucción, lo que lo hace muy lento.

### Translation Lookaside Buffers

Veamos ahora esquemas ampliamente implementados para acelerar la paginación y para manejar grandes espacios de direcciones virtuales, empezando por el primero. El punto de partida de la mayoría de las técnicas de optimización es que la tabla de páginas está en memoria. Potencialmente este diseño tiene un enorme impacto en el rendimiento. Consideremos, por ejemplo, una instrucción de 1 byte que copia un registro en otro. En ausencia de paginación, esta instrucción sólo hace una referencia a memoria, para buscar la instrucción. Con paginación se necesitará al menos una referencia de memoria adicional para poder acceder a la tabla de paginación. Dado que la velocidad de ejecución suele estar limitada por la velocidad que la CPU puede obtener instrucciones y datos de la memoria, tener que hacer 2 referencias de memoria por cada referencia de memoria, reduce el rendimiento a la mitad. En estas condiciones nadie utilizaría paginación.

Los diseñadores de computadoras sabían de este problema por años y trajeron una solución. Su solución se basói en la observación de que la mayoría de programas tienden a hacer un gran número de referencias a un pequeño número de páginas, y no al revés. Así, sólo una pequeña fracción de las entradas de la tabla de página se lee mucho; el resto apenas se utiliza.

La solución que se ideó fue dotar a las computadoras de un pequeño dispositivo de hardware para asignar direcciones virtuales a direcciones físicas sin pasar por la tabla de páginas. El dispositivo, llamado **TLB (Translation Lookaside Buffer)** o aveces **associative memory** es mostrada en la figura 3-12. Se encuentra usualmente en el MMU y consiste en un número pequeño de entradas, 8 en este ejemplo, pero raramente más de 256. Cada entrada contiene información de una página, incluyendo el número de página virtual, un bit que se setea cuando la página es modificada, el codigo de protección(read/write/execute permissions), y el page frame físico en el cual se localiza la página. Estos campos tienen correspondencia de uno a uno con los campos de la tabla de página, excepto por el numero de página virtual, el cual no se necesita en la tabla de página. Otro bit indica si la entrada es válida (es decir, está en uso) o no.

Un ejemplo que puede generar el TLB de la figura 3-12 es un proceso con un bucle que abarca las páginas virtuales 19, 20 y 21, entonces estas entradas de TLB tienen codigos de protección para leer y ejecutar. Los datos principales que se están utilizando(por ejemplol, una matriz que se está procesando) están en las páginas 129 y 130. La página 140 contiene los indices usados en los calculos del array. Finalmente, la pila se encuentra en las páginas 860 y 861.

![figure3-12](https://github.com/gabo52/SistemasOperativos/blob/main/figures/Chapter3/figure3-12.png?raw=true)

Ahora veamos como el TLB funciona. Cuando una dirección virtual es presentada al MMU para traducirse, el hardware primero revisa para ver si el número de página virtual está presente en el TLB comparándolo con todas las entradas simultáneamente. Para ello se necesita un hardware especial, del que disponen todas las MMU con TLB. Si se encuentra una coincidencia válida y el acceso no viola los bits de protección, el page frame se toma directamente del TLB, sin ir a la tabla de páginas. Si el número de página está presente en la TLB, pero la instrucción está intentando escribir en una página de solo lectura, se genera un fallo de protección.

El caso interesante es qué pasa cuando el número de página virtual no se encuentra en el TLB. El MMU detecta el fallo y realiza una búsqueda ordinaria en la tabla de páginas. A continuación, desaloja una de las entradas de la TLB y la sustituye por la entrada de la tabla de páginas que acaba de consultar. De este modo, si esa página se utiliza de nuevo pronto, la segunda vez resultará en un acierto en la TLB en lugar de un fallo. Cuando se elimina una entrada de la TLB, el bit modificado se copia denuevo en la entrada de tabla de páginas en memoria. Los otros valores ya están ahí excepto el bit de referencia. Cuando el TLB es cargado de la tabla de página, todos los campos son tomados de memoria.

### Software TLB Management

Hasta ahora, hemos asumido que cada máquina con memoria virtual paginada tiene tablas de paǵina reconocidas por el hardware, además de un TLB. En este diseño, la gestión del TLB y el manejo de los fallos del TLB son realizados enteramente por el hardware de la MMU. Los traps al sistema operativo ocurren sólo cuando una página no está en memoria.

En el pasado, asumir esto estaba bien. Sin embargo, muchas máquinas RISC, incluyendo el SPARC, MIPS, y(la ahora muerta) HP PA, hacen casi toda esta gestión de páginas en software. En estas máquinas, las entradas de TLB son explícitamente cargadas por el sistema operativo. Cuando ocurre un miss en el TLB, en lugar de que la MMU vaya a las tablas de página para encontrar y recuperar la referencia de página necesaria, simplemente genera un fallo en la TLB y deja el problema en manos del sistema operativo. El sistema debe encontrar la página, remover una entrada del TLB, ingresar la nueva entrada, y reiniciar la instrucción que falló. Y, por supuesto, todo esto debe hacerse en un puñado de instrucciones porque los fallos de TLB ocurren con muchas más frecuencia que los fallos de página.

Sorprendentemente, si la TLB es moderadamente grande (digamos, 64 entradas) para reducir la tasa de fallos, la gestión por software de la TLB resulta ser aceptablemente eficiente.

La ventaja principal es una MMU mucho más sencilla, que libera una cantidad considerable de espacio en el chip de la CPU para cachés y otras funciones que pueden mejorar el rendimiento. Uhlig et al. (1994) analizan la gestión de TLB por software.

Se han desarrollado varias estrategias años atrás para mejorar el rendimiento de las máquinas que manejan el TLB en su software. Un enfoque ataca tanto la reducción de fallos en la TLB como la reducción del coste de un fallo en la TLB cuando ocurre (Bala et al., 1994). Para reducir fallos en la TLB aveces el sistema operativo puede usar su propia intuición para averiguar qué páginas es probable que se utilicen a continuación y precargar entradas para ellas en la TLB. Por ejemplo, cuando un proceso de cliente envía un mensaje a un proceso de servidor en una misma máquina, es muy probable que el servidor tenga que ejecutarse pronto. Sabiendo esto, mientras se procesa el trap para hacer el envío, el sistema también puede comprobar dónde están las páginas de código, datos y pila del servidor y asignarlas antes de que tengan la oportunidad de causar fallos en la TLB. 

La forma normal de procesar un fallo del TLB, ya sea en hardware o en software, es ir a la tabla de páginas y realizar las operaciones de indexación para localizar la página referenciada. El problema de realizar esta búsqueda en software es que las páginas que contienen la tabla pueden no estar en el TLB, lo que provocará fallos adicionales en la TLB durante el procesamiento. Estos fallos pueden reducirse manteniendo una caché de software grande(por ejemplo, de 4 KB) de entradas TLB en una ubicación fija cuya página se mantenga siempre en el TLB. Comprobando primero la caché de software, el sistema puede reducir sustancialmente los fallos en la TLB.

Cuando un software de manejo de TLB es usado, es esencial entender la diferencia entre distintos tipos de miss. Un **soft miss** ocurre cuando la página referenciada no se encuentra en el TLB, pero está en memoria. Todo lo que se necesita acá es que el TLB se actualice. No se necesitan I/O del disco. Normalmente un soft miss tarda entre 10-20 instrucciones para completarse en un par de nanosegundos. En contraste, un **hard miss** ocurre cuando la página no está en memoria(y por supuesto, tampoco en el TLB). Se necesita un acceso al disco para traer la página, la cual puede tomar varios milisegundos, dependiendo el tipo de disco que se esté utilizando. Un hardmiss es fácilmente un millón de veces más lento que un soft miss. La búsqueda para el mapeo en la jerarquía de tablas de páginas se conoce como **page table walk**.

En realidad, es peor que eso. Un fallo no es solo soft or hard. Algunos fallos son ligeramente más soft o hard que otros. Por ejemplo, supongamos que el **page table walk** no encuentra la página en la tabla de páginas del proceso y el programa incurre en un fallo de página. Hay 3 posibilidades. Primero, la página puede estar en memoria, pero no en la tabla de página del proceso. En este caso, la página pudo haber sido traida del disco por otro proceso, entonces, no necesitaremos acceder al disco denuevo, sinos simplemente debemos mapear apropiadamente en las tablas de páginas. Este es un miss bastante suave, el cual es conocido como **minor page fault**. Segundo, un **major page fault** ocurre si la página que se necesita debe ser traída del disco. Tercero, es posible que el programa simplemente haya accedido a una dirección inválida y no sea necesario añadir ninguna asignación en la TLB. En ese caso, el sistema operativo normalmente mata el programa con un **segmentation fault**. Solo en este caso el programa hizo algo mal. Todos los demás casos son solucionados por el hardware y/o el sistema operativo, a costa de algo de rendimiento.

## 3.3.4 Page Tables for Large Memories

Los TLBs pueden ser usados para acelerar la traducción de direcciones de virtual a físico respecto al esquema original de page-table-in-memory. Este no es el único problema que debemos enfrentar. Otro problema es cómo enfrentar con los espacios de direcciones virtuales que son bastante largos. A continuación veremos 2 formas de lidiar con esto.

### Multilevel Page Tables

Como primera aproximación, considere el uso de una **multilevel page table**. En la figura 3-13 se muestra un ejemplo sencillo. En la figura 3-13(a) tenemos una dirección virtual de 32 bits que se divide en un campo PT1 de 10 bits, un campo PT2 de 10 bits y un campo Offset de 12 bits. Como los offset son de 12 bits, las páginas son de 4KB y hay un total de 2^20 de ellas. 

El secreto del método de tablas de página multinivel es evitar mantener todas las tablas de páginas en memoria todo el tiempo. En particular, aquellos que no lo necesitan, no deben tenerse cerca. Supongamos por ejemplo, que un proceso necesita 12 megabytes: los 4 megabytes de abajo para el program text, los 4 siguientes para la data y los 4 megabytes de arriba para el stack. En el medio del top de la data y el la parte de bajo hay un hueco inmenso que no se usa.

En la figura 3-13(b) vemos como los 2 niveles de la tabla trabajan. En la izquierda vemos el top level de la tabla de página, con 1024 entradas, correspondiendo a los 10 bit del campo PT1. Cuando una dirección virtual es presentada al MMU, primero se extrae el campo PT1 y usar este valor como índice en el top level de la tabla de página. En cada una de esas 1024 entradas en el top-level de la tabla de página se representan 4M dado que los 4GB enteros (es decir, 32 bits) de espacio de memoria virtual se han dividido en trozos de 4096 bytes.

La entrada localizada por indexación en la tabla de página de nivel superior proporciona la dirección o el page frame de una tabla de páginas de segundo nivel. La entrada 0 de la tabla de páginas de nivel superior apunta a la tabla de página para los datos y la entrada 1023 apunta a la tabla de páginas para la pila. Las otras entradas sombreadas no se utilizan. El campo PT2 se utiliza ahora como índice en la tabla de páginas de segundo nivel seleccionada para encontrar el número de marco de página para la propia página.

![figure3-13](https://github.com/gabo52/SistemasOperativos/blob/main/figures/Chapter3/figure3-13.png?raw=true)

Como ejemplo, consideremos una dirección virtual de 32 bits 0x00403004 (4,206,596 en decimal), que tiene 12.292 bytes dentro de los datos. Esta dirección virtual corresponde al PT1 = 1, PT2 = 3, and offset  = 4. el MMU primero usa PT1 para el índice en el top level de la tabla de páginas y obtiene la entrada 1, la cual corresponde a las direcciones de 4M a 8M -1. Luego usa el PT2 para el índice en el segundo nivel de la tabla de página  y extraer la entrada 3, que corresponde a las direcciones 12288 a 16383 con un trozo de 4M(es decir, las direccions absolutas 4.206.592 a 4.210.687). Esta entrada contiene el numero de page frame que contiene la dirección virtual 0x00403004. Si esta página no está en memoria, el *Present/Absent* bit en la entrada de la tabla de página va a tener el valor 0, causando un fallo de paǵina. Si la página está presente en memoria, el número de page frame tomado del segundo nivel de tabla de página es combinado con el offset (4) para construir la dirección física. Esta dirección es puesta en el bus y es enviada a memoria.  


Algo interesante a notar en la figura 3-13 es que aunque el espacio de direcciones contiene más de un millón de páginas, sólo se necesitan 4 tablas de página: la tabla del nivel superior, y las tablas del segundo nivel de 0 a 4M(para el program text), 4M a 8M(para la data) y la parte superior de 4M(para el stack). Los *Present/absent* bits en las 1021 entradas restantes de la tabla de páginas de nivel superior se ponen a 0, forzando un fallo de página si alguna vez se acceden a ellas. Si esto ocurre, el sistema operativo se dará cuenta que el proceso está intentando hacer referencia a una memoria que no le corresponde y tomará las medidas oportunas, como enviarle una señal o matarlo. En este ejemplo hemos elegido número redondos para los distintos tamaños y hemos escogido PT1 igual a PT2, pero en la práctica real, por supuesto que es posible que tengan otros valores.

Los 2 niveles de tablas de página en la figura 3-13 pueden ser expandidas a 3, 4 o más niveles. Niveles adicionales dan más flexibilidad. Por ejemplo, el procesador 80386 de 32 bits de Intel(lanzado en 1985) era capaz de direccionar hasta 4GB de memoria, utilizando una tabla de páginas de 2 niveles que consistía en un directorio de páginas cuyas entradas apuntaban a tablas de páginas, las cuales, a su vez. apuntaban a los marcos de páginas de 4KB reales. Tanto el directorio d páginas como las tablas de página contenían 1024 entradas cada uno, lo que daba un total de 2^(10)*2^(10)*2^(12) = 2^32 bytes direcionnables, según lo deseado.

10 años después el Pentium Pro introdujo otro nivel: el **page directory pointer table**. Además amplió cada entrada de cada nivel de jerarquía de la tabla de página de 32 bits a 64 bits, para poder direccionar memoria por encima del límite de los 4GB. Como sólo tenía 4 entradas en la tabla de punteros del directorio de páginas, 512 en cada directorio de páginas y 512 en cada tabla de páginas la cantidad total de memoria que podía direccionar seguía estando limitada a un máximo de 4GB. Cuando se añadió el soporte adecuado de 64 bits a la familia de 64 bits a la familia de x86 (originalmente por AMD), el nivel adicional podría haberse llamado "page directory pointer table pointer" o algo igual de horrible. Afortunadamente, no lo hicieron. La alternativa que inventaron, "**mapa de página de nivel 4**", puede que tampoco sea un nombre muy pegadizo, pero al menos es corto y un poco más claro. En cualquier caso, estos procesadores utilizan ahora las 512 entradas de todas las tablas, lo que supone una cantidad de memori direccionable de 2^9 *2^9 *2^9 *2^9 *2^12 = 2^48 bytes. Podrían haber añadido otro nivel, pero probablemente pensaron que 256 TB serían suficientes durante un tiempo.

### Inverted Page Tables

Una alternativa a los niveles que siempre crecen en una jerarquía de paginación es conocida como **inverted page tables**. Fueron utilizadas por primera vez por procesadores como el Power PC, el UltraSPARC y el Itanium(a veces llamado Itanic, ya que no fue el éxito que Intel esperaba). En este diseño hay una entrada por page frame en la memoria real, en lugar de una entrada por página del espacio de direcciones virtual. Por ejemplo, con direcciones virtuales de 64 bits, una página de 4KB de tamaño y 4GB de RAM, una inverted page table requiere solo 1,048,576 entradas. La entrada lleva la cuenta de cuál(proceso, página virtual) se encuentra en el marco de página.

Aunque las tablas de paǵinas invertidas ahorran mucho espacio, al menos cuando el espacio de direcciones virtuales es mucho mayor que la memoria física, tiene un grave inconveniente: la traducción de virtual a física se hace mucho más díficil. Cuando el proceso n hace referencia a la página virtual p, el hardware ya no puede encontrar la página física utilizando p como índice en la tabla de páginas. En su lugar, debe buscar una entrada (n,p) en toda la tabla de páginas invertida. Además, esta búsqueda debe realizarse en cada referencia de memoria, no sólo en los fallos de página. Buscar en una tabla de 256K en cada referencia de memoria no es la forma de hacer que tu máquina sea muy rápida.

La forma de salir de este dilema es hacer uso del TLB. Si el TLB puede contener todas las páginas que son muy utilizadas, la traducción puede realizarse tan rápido como con las tablas de páginas normales. Sin embargo, si se pierde la TLB, la tabla de páginas invertida debe buscarse en el software. Una forma factible de realizar esta búsqueda es tener una tabla hash que contenga las direcciones virtuales. Todas las páginas virtuales actualmente en memoria que tienen el mismo valor hash son encadenadas juntas, como se muestra en la figura 3-14. Si la tabla hash tiene tantas ranuras como páginas físicas tiene la máquina, la cadena promedio tendrá solo una entrada, acelerando enormemente el mapeo. Una vez que se ha encontrado el número de page frame, el nuevo par (virtual, físico) se introduce en la TLB.

![figure 3-14](https://github.com/gabo52/SistemasOperativos/blob/main/figures/Chapter3/figure3-14.png?raw=true)

Las tablas de páginas invertidas son comunes en máquina de 64 bits porque incluso con un tamaño de página muy grande, el número de entradas de la tabla de páginas es gigantesco. Por ejemplo, con páginas de 4MB y direcciones virtuales de 64 bits, se necesitan 2^42 entradas en la tabla de páginas.  En Talluri et al. (1995) se pueden encontrar otros enfoques para manejar memorias virtuales grandes.
