# PAGE REPLACEMENT ALGORITHMS

Cuando ocurre un fallo de página, el sistema operativo debe escoger una página como victima(para removerla de la memoria) para hacer espacio para la pagina entrante. Si la página que va a ser removida ha sido modificada mientras estaba en memoria, esta debe ser sobreescrita en el disco para mantener al disco actualizado. Si, de todos modos, la página no ha sido cambiada(por ejemplo tiene el program text), el disco tiene la copia actualziada, por lo que no necesita sobreescribirla. La página que se va a leer sobrescribe la página que se está desalojando.

Mientras sea posible escoger una página random como víctima para cada fallo de página, el rendimiento del sistema es mucho mejor si la página escogida no es muy usada. Si la página muy usada es removida, esta probablemente tenga que volver pronto, resultando en un overhead extra. Se debe realizar mucho trabajo en el tema de reemplazo de algoritmos de páginas, tanto experimental como teoricamente. A continuación describiremos algunas de las más importantes.

No hay que olvidar que el problema del "cambio de página" también se da en otros ámbitos del diseño de computadoras. Por ejmplo, la mayoría de computadoras tiene una o más memorias cache con bloques de 32 o 64 bytes. Cuando la caché se llena, se debe escoger algún bloque para ser removido. Este problema precisamente es el mismo al reemplazo de páginas excepto por el tiempo de escala menor(tiene que realizarse en pocos nanosegundos, no en milisegundos como en el page replacement). La razón para el corto tiempo de escala es que los fallos de bloques de la caché se satisfacen desde la memoria principal, que no tiene tiempo de búsqueda ni latencia rotacional.

Un segundo ejemplo es en una Web server. El servidor puede mantener cierto número de página muy usadas en la memoria caché. Como sea, cuando la memoria caché está llena y una nueva página es referenciada, se debe realizar la decisión de escoger una página Web como víctima. Las consideraciones son similares a las de la memoria virtual, excepto por el hecho de que las paginas de Web no se modifican en la caché, por lo que siempre debe haber una copia actualizada "en el disco". En sistema de memoria virtual, las páginas en memoria principal pueden estar limpias o sucias.

En todos los algoritmos de reemplazo que estudiaremos a continuación, surge un cierto problema: cuando una página es victima en memoria, ¿tiene que ser una de las páginas propias del proceso que falla, o puede ser una página perteneciente a otro proceso? En el primer caso, estamos limitando cada proceso con un número de páginas, en el segundo caso no. Ambas son posibilidades. Vamos a ver denuevo este punto en la sección 5.3.1.

## 3.4.1 The Optimal Page Replacement Algorithm

El mejor algoritmo de reemplazo es fácil de describir, pero imposible de implementar en la actualidad. Es de esta forma. Cuando ocurre uin fallo de página algunos sets de páginas se encuentrann en memoria. Una de estas páginas va a ser referenciada en la siguientes instrucciónes(la página contiene aquella instruccion/es). Otras páginas pueden no ser referenciadas, hasta 10, 100 o quizás 1000 instrucciones después. Cada página puede ser etiquetada con el número de instrucciones que serán ejecutadas antes de que esa página sea referenciada por primera vez.

El algoritmo óptimo de reemplazo de página dice que la paǵina con la etiqueta más alta debe ser removida. Si una página no va a seer usada por 8 millones de instrucciones y otra página no va a ser usada por 6 millones de instrucciones, la eliminación del primero empuja el fallo de página que lo recuperará lo más lejos posible en el futuro. Las computadoras, como las personas, intentan aplazar los acontecimientos desagradables todo lo que pueden.

El único problema con este algoritmo es que es imposible de realizar. Al momento del fallo de página, el sistema operativo no tiene forma de saber que otras páginas van a ser referenciadas en el futuro(Vimos una situación similar con el shortest-job-first scheduling algorithm- como el sistema puede saber qué trabajo es más corto?).De todas formas, ejecutando el programa en un simulador, y manteniendo un registro de todas las referencias de página es posible implementar el optimal page replacement en una *segunda* ejecución usando la información de referencias de página de la *primera* ejecución.

De esta forma, es posible comparar el desempeño de algoritmos realizables con el mejor posible. Si un sistema operativo logra un rendimiento de solo un 1% pero que el optimal algorithm, el esfuerzo invertido en buscar un algoritmo mejor supondrá como mucho un 1% de mejora.

Para evitar alguna posible confusión, se debe aclarar que este registro de referencias de página es para solo un programa medido solo con un input específico. El algoritmo de sustitución de páginas que se deriva de él es, por tanto, específico para ese programa y esos datos de entrada. De todas formas este algoritmo es usado para evaluar los algoritmos de reemplazo de página, no tiene uso en sistemas prácticos. Debajo veremos algoritmos que son útiles en sistemas reales.

## 3.4.2 The Not Recently Used Page Replacement Algorithm

Para que el sistema pueda recolectar estadísticas de uso de páginas, muchas computadores con memoria virtual tiene 2 bits de estado, R y M, asociados con cada página. R es 1 cuando la página es referenciada(escrita o leída). M es 1 cuando la página es escrita(es decir, modificada). Los bits son contenidos en cada entrada de la tabla de página, como se ve en la figura 3-11. Es importante darse cuenta que estos bits pueden actualizarse en cada referencia a memoria, por lo que es esencial que sean seteados por el hardware. Una vez que un bit se ha puesto a 1, dice 1 hasta que el sistema operativo lo reinicia.

Si el hardware no tiene estos bits, estos pueden ser simulados con el fallo de página del sistema operativo y los mecanismos de interrupción por clock. Cuando comience un proceso, todos las entradas de la tabla página se marcan como no halladas en meoria. Apenas se referencie una página, ocurre un fallo. El sistema operativo setea el bit R(en sus tablas internas), cambia la entrada a la tabla de página para apuntar a la tabla correcta con el modo READ ONLY y reinicia la instrucción. Si la página es modificada subsecuentemente, va a ocurrir otro fallo de página, permitiendo al sistema operativo setear el bit M y cambiar el modo de la página a READ/WRITE. Los bits R y M pueden ser usados para construir un algoritmo de página simple como veremos. 

Cuando un proceso comienza, ambos bits de página son puestos en 0 por el sistema operativo. Periodicamente(en cada interrupción de clock), el bit R es limpiado, para distinguir las páginas que no han sido referenciadas recientemente con aquellas que sí. Cuando ocurre un fallo de página, el sistema operativo inspecciona todas las páginas y las divide en 4 categorías basadas en sus valores de los bits R y M.

- Class 0: not referenced, not modified.
- Class 1: not referenced, modified.
- Class 2: referenced, not modified.
- Class 3: referenced, modified.

Aunque la clase 1 parezca, a primera vista, imposible, esto ocurre cuando la página de la clase 3 recibe un clear en su bit R por un clock interrupt. Los clock interrupt no limpian el bit M, dado que esta información es necesaria para saber si hay que escribir la página en el disco o no. Limpiar el R pero no el M nos lleva a la clase 1.

El algoritmo **NRU (Not Recently Used)** elimina una página al azar de la clase no vacía con el número más bajo. Implícitamente este algoritmo es la idea de que es mejor remover una página modificada que no fue referenciada por lo menos una vez en el clock tick(el cual es típicamente de unos 20 msec) que una página limpia pero que es muy usada. La principal atracción del NRU es que es fácil de entender, moderadamente eficiente para implementar y da un rendimiento que aunque ciertamente no es óptimo, puede ser adecuado.

## 3.4.3 The First-In, First-Out (FIFO) Page Replacement Algorithm

Otro algoritmo de paginación con poco overhead es el **FIFO (First-In, First-Out) algorithm**. Para ilustrar como este funciona, consideremos un supermercado que tiene suficientes estanterías para mostrar exactamente k productos diferentes. Un día, una compañía introduce una nueva comida-Yogur biológico liofilizado instantáneo que puede reconstituirse en el microondas. Como suceso inmediato nuestro supermercado finito debe deshacerse de un producto antiguo para colocar el nuevo.

Una posibilidad es ver el producto más antiguo que ha estado vendiendo el supermercado y deshacerse de ella alegando que ya no interesa a nadie. En efecto, los supermercados mantienen una lista de todos los productos actualmente en venta en el orden que han sido introducidos. El nuevo va al final de la lista, el primero en la lista es botado.

Se puede aplicar la misma idea a un algoritmo de página. El sistema operativo mantiene una lista de todas las páginas actualmente en memoria, con la más reciente en llegada en la cola y la menos reciente en llegada en la cabeza. En un fallo de página, la página de la cabeza es removida y la nueva página es añadida en la cola de la lista. 

Cuando se aplica a las tiendas, el FIFO puede eliminar la cera del bigote, pero también la harina, la sal o la mantequilla. Cuando se aplica a los ordenadores surge el mismo problema: la página más antigua puede seguir siendo útil. Por esta razón, el FIFO en su forma pura rara vez se utiliza.

## 3.4.4 The Second-Chance Page Replacement Algorithm

Se usa una modificación simple a FIFO para evitar el problema de eliminar una página muy usada, para esto se inspecciona el bit R de la última página. Si este es 0, la página es antigua y no se utiliza, por lo que se reemplazaría inmediatamente. Si el bit R es 1, el bit se borra, la página se coloca al final de la lista de páginas y su tiempo de carga se actualiza como si acabara de llegar a la memoria. 

El funcionamiento de este algoritmo, llamado de **second chance**, se muestra en la Fig. 3-15. En la Fig. 3-15(a) vemos las páginas A a H guardadas en una lista enlazada y ordenadas por el tiempo de llegada a memoria.

![figure3-15](https://github.com/gabo52/SistemasOperativos/blob/main/figures/Chapter3/figure3-16.png?raw=true)

Supongamos que el fallo de página ocurre en el tiempo 20. La página más antigua es A, la cual llego en tiempo 0, cuando comenzó el proceso. Si A tiene el bit R en 0, se expulsa de la memoria, ya sea escribiéndose en el disco (si está sucio), o simplemente abandonándose (si está limpio).  Por otro lado, si el bit R está activado, A se coloca al final de la lista y su ''tiempo de carga'' se restablece al tiempo actual (20). El bit R también se borra. La búsqueda de una página adecuada continúa con B.

Lo que second chance busca es una página antigua que no haya sido referenciada en el intervalo de reloj más reciente.  Si todas las páginas han sido referenciadas, second chance se convierte en FIFO puro. Específicamente, imagine que todas las páginas en la Fig. 3-15(a) tienen sus bits R activados. Una a una, el sistema operativo mueve las páginas al final de la lista, borrando el bit R cada vez que añade una página al final de la lista. Finalmente, vuelve a la página A, que ahora tiene su bit R borrado. En este punto, A es desalojada. De este modo, el algoritmo siempre termina.

## 3.4.5 The Clock Page Replacement Algorithm

Aunque second chance es un algoritmo razonable, es innecesariamente ineficiente dado que mueve constantemente páginas alrededor de la lista. Una mejor forma es mantener todos los page frame en una lista circular en la forma de un reloj, como vemos en la figura 3-16. Las manecillas señalan la página más antigua.

![figure3-16](https://github.com/gabo52/SistemasOperativos/blob/main/figures/Chapter3/figure3-16.png?raw=true)

Cuando ocurre un fallo de página, la página que es apuntada por la manecilla es inspeccionada. Si el bit R es 0, la página es eliminada, la nueva página es insertada en el reloj en esa posición y la manecilla avanza a la siguiente posición. Este proceso se repite hasta que se encuentre una página con el bit R=0. No en vano, este algoritmo se denomina **clock**.

## 3.4.6 The Least Recently Used (LRU) Page Replacement Algorithm

Una buena aproximación al optimal algorithm es basado en la observación de que las páginas que han sido referenciadas continuamente en las últimas instrucciones probablemente también sean muy usadas pronto. Por el contrario, las páginas que no han sido usadas por un buen tiempo probablemente permanecerán sin usarse por un buen tiempo. Esta estrategia es llamada **LRU(Least Recently Used)** paging.

Aunque LRU es teóricamente realizable, no es barato ni mucho menos. Para implementar completamente LRU, es necesario mantener una lista enlazada de todas las páginas en memoria, con la página usada más recientemente al principio y la página usada menos recientemente al final. La dificultad está en que la lista debe actualizarse en cada referencia de memoria.  Encontrar una página en la lista, borrarla y luego moverla a la parte delantera es una operación que consume mucho tiempo, incluso en hardware (suponiendo que se pudiera construir dicho hardware).

De todas formas, existen otras formas de implementar LRU con un hardware especial. Consideremos la forma más simple primero. Este método requiere equipar al hardware con un contador de 64 bits, C, que es automáticamente incrementado en cada instrucción. 
Además, cada entrada de la tabla de páginas también debe tener un campo lo suficientemente grande como para contener el contador. Antes de cada referencia de memoria, el valor actual de C se guarda en la entrada de la tabla de página para la página que acaba de ser referenciada. Cuando ocurra un fallo de página, el sistema operativo examina todos los contadores en la tabla de página para encontrar el menor. Esta página es la menos usada recientemente.

## 3.4.7 Simulating LRU in Software

Aunque el algoritmo LRU anterior es (en principio) realizable, pocas máquinas, o ninguna, disponen del hardware necesario. En su lugar, se necesita una solución que pueda implementarse en software. Una posibilidad es el algoritmo **NFU (Not Frequently Used)**.  Requiere un contador de software asociado a cada página, inicialmente cero. En cada interrupción del reloj, el sistema operativo escanea todas las páginas de la memoria. Para cada página, el bit R, que es 0 o 1, se añade al contador. Los contadores mantienen un registro aproximado de la frecuencia con la que se ha hecho referencia a cada página. Cuando se produce un fallo de página, se elige la página con el contador más bajo para sustituirla.

El principal problema con NFU es que es como un elefante: nunca olvida nada. Por ejemplo, en un compilador multipase, las páginas que se utilizaron mucho durante el paso 1 pueden seguir teniendo un recuento alto en pases posteriores. De hecho, si la pasada 1 tiene el tiempo de ejecución más largo de todas las pasadas, las páginas que contienen el código para las pasadas posteriores pueden tener siempre recuentos más bajos que las páginas de la pasada 1. En consecuencia, el sistema operativo eliminará las páginas útiles en lugar de las páginas que ya no se utilicen. 

Afortunadamente, una pequeña modificación a NFU hace posible simular LRU un poco mejor. La modificación tiene 2 partes. En primer lugar, los contadores se desplazan 1 bit a la derecha antes de añadir el bit R. En segundo lugar, el bit R se añade al bit situado más a la izquierda que al situado más a la derecha. En segundo lugar, el bit R se añade al bit situado más a la izquierda en lugar de al situado más a la derecha.

La figura 3-17 muestra como el algoritmo modificado, conocido como **aging** funciona. Supongamos que antes del primer tick del reloj, para las páginas de 0 a 5 tenemos los valores 1, 0, 1, 0, 1 y 1 respectivamente (paǵina 0 es 1, paǵina 1 es 0, paǵina 2 es 1, paǵina 3 es 0, paǵina 4 es 1 y la ṕagina 5 es 1). En otras palabras, entre el tick 0 y el tick 1, las páginas 0, 2, 4 y 5 han sido referenciada, seteando su bit a 1, mientras que las demás se mantienen en 0. Una vez desplazados los seis contadores correspondientes e insertado el bit R a la izquierda, tienen los valores mostrados en la Fig. 3-17(a). Las cuatro columnas restantes muestran los seis contadores después de las siguientes cuatro pulsaciones de reloj. 

Cuando se produce un fallo de página, se elimina la página cuyo contador es el más bajo.  Es claro que una página que no ha sido referenciada por, digamos, cuatro ticks de reloj tendrá cuatro ceros a la izquierda en su contador y por lo tanto tendrá un valor más bajo que un contador que no ha sido referenciado por tres ticks de reloj.

![figure3-17](https://github.com/gabo52/SistemasOperativos/blob/main/figures/Chapter3/figure3-17.png?raw=true)

Este algoritmo difiere de LRU en 2 importantes aspectos. Considere las páginas 3 y 5 de la Fig. 3-17(e). Ninguna ha sido referenciada durante dos ticks de reloj; ambas fueron referenciadas en el tick anterior. De acuerdo con LRU, si una página debe ser reemplazada, deberíamos elegir una de estas dos. El problema es que no sabemos cuál de ellas fue referenciada por última vez en el intervalo entre el tic 1 y el tic 2. Al registrar sólo 1 bit por intervalo de tiempo, hemos perdido la capacidad de distinguir las referencias tempranas en el intervalo de tiempo de las posteriores. Todo lo que podemos hacer es removar la página 3, porque la página 5 ha sido referenciada 2 tics antes y la página 3 no.

La segunda diferencia entre LRU y aging es que en aging los contadores tiene un número finito de bits(8 bits en este ejemplo), el limita el horizonte del pasado. Supongamos que 2 página tienen el valor de 0. Todo lo que podemos hacer es escoger una de ellas aleatoriamente. En realidad, es posible que una de las páginas haya sido referenciada por última vez hace nueve ticks y la otra hace 1000 ticks. No tenemos forma de saberlo. En la práctica, sin embargo, 8 bits suelen ser suficientes si el tick del reloj es de unos 20 mseg. Si una página no ha sido referenciada en 160 mseg, probablemente no sea tan importante.

## 3.4.8 The Working Set Page Replacement Algorithm

En la forma pura de paginación, los procesos comienzan con ninguna de sus páginas en memoria. Apenas el CPU trate de encontrar alguna instrucción, se ocasionará un fallo de página, causando que el sistema operativo traiga la página que contenga la primera instrucción. Otros fallos de página para variables globales y la pila suelen seguir rápidamente. Después de un tiempo, el proceso tiene la mayoría de las páginas que necesita y se estabiliza para funcionar con relativamente pocos fallos de página. Esta estrategia se denomina **demand paging** porque las páginas se cargan sólo bajo demanda, no por adelantado.

Por supuesto, es bastante fácil escribir un programa de prueba que sistemáticamente lea todas las páginas en un gran espacio de direcciones, causando tantos fallos de página que no haya suficiente memoria para contenerlos todos. Afortunadamente, la mayoría de los procesos no funcionan así. Muestran una **locality of reference**, lo que significa que durante cualquier fase de ejecución, el proceso hace referencia sólo a una fracción relativamente pequeña de sus páginas. Cada paso de un compilador multipaso, por ejemplo, sólo hace referencia a una fracción de todas las páginas, y a una fracción diferente.

El set de paginas que un proceso usa frecuente es el **working set**. Si el working set entero es en memoria, el proceso va a ejecutarse sin causar muchos fallos de página a menos que se mueva a otra fase de ejecución(por ejemplo, al siguiente paso del compilador). Si la memoria disponible es demasiado pequeña para mantener todo el working set, el proceso va a causar muchos fallos de página y va a ejecutarse lentamente, dado que la ejecución de una instrucción tarda unos pocos nanosegundos y la lectura de una página desde el disco normalmente tarda 10 mseg, a un ritmo de una o dos instrucciones cada 10 mseg, tardará siglos en terminar.  Se dice que un programa que provoca fallos de página cada pocas instrucciones es **thrashing** (Denning, 1968b).

En un sistema de multiprogramación, los procesos suelen trasladarse al disco(es decir, sus páginas son removidas de la memoria) para cederle el turno a otros procesos en el CPU. Se plantea la cuestion de qué hacer cuando un proceso es devuelto. Técnicamente, no se debe hacer nada. El proceso sólo causará fallos de página hasta que su conjunto de trabajo se haya cargado. El problema es que tener numerosos fallos de página cada vez que se carga un proceso es lento, y también desperdicia mucho tiempo de CPU, ya que el sistema operativo tarda unos milisegundos de CPU en procesar un fallo de página.

Sin embargo, varios sistemas de páginación tratan de tener un registro del working set de cada proceso y se aseguran de que estén en memoria antes de que el proceso se ejecute. Este enfoque se denomina **working set model**. Fue diseñado para reducir el page fault rate. Cargar las páginas *antes* permiten a los procesos ejecutarse en algo llamado **prepaging**. Tenga en cuenta que el conjunto de trabajo cambia con el tiempo.

Desde hace tiempo se sabe que los programas rara vez hacen referencia a su espacio de direcciones de manera uniforme, sino que las referencias tienden a agruparse en un pequeño número de páginas. Una referencia de memoria puede buscar una instrucción o un dato, o puede almacenar datos. En cualquier instante de tiempo, t, existe un conjunto formado por todas las páginas utilizadas por las k referencias de memoria más recientes. Este conjunto, w(k, t), es el working set. Dado que las k = 1 referencias más recientes deben haber utilizado todas las páginas utilizadas por las k > 1 referencias más recientes, y posiblemente otras, w(k, t) es una función monotónicamente decreciente de k. El límite de w(k, t) a medida que k se hace grande es finito porque un programa no puede hacer referencia a más páginas de las que contiene su espacio de direcciones, y pocos programas utilizarán cada página. La Figura 3-18 muestra el tamaño del conjunto de trabajo en función de k.

El hecho de que la mayoría de los programas accedan aleatoriamente a un pequeño número de páginas, pero que este conjunto cambie lentamente en el tiempo explica la rápida subida inicial de la curva y luego la subida mucho más lenta para k grandes. Por ejemplo, un programa que está ejecutando un bucle que ocupa dos páginas utilizando datos en cuatro páginas puede hacer referencia a las seis páginas cada 1000 instrucciones, pero la referencia más reciente a alguna otra página puede ser un millón de instrucciones antes, durante la fase de inicialización. Debido a este comportamiento asintótico, el contenido del conjunto de trabajo no es sensible al valor de k elegido. 

![figure3-18](https://github.com/gabo52/SistemasOperativos/blob/main/figures/Chapter3/figure3-18.png?raw=true)

Dicho de otro modo, existe una amplia gama de valores de k para los que se modifica el conjunto de trabajo. Dado que el conjunto de trabajo varía lentamente con el tiempo, es posible hacer una estimación razonable de las páginas que se necesitarán cuando se reinicie el programa basándose en el conjunto de trabajo que tenía la última vez que se detuvo. El prepaging consiste en cargar estas páginas antes de reanudar el proceso.

Para implementar el working set model, es necesario que el sistema operativo mantenga un registro de qué paginas se encuentran en el working set. Disponer de esta información también conduce inmediatamente a un posible algoritmo de sustitución de páginas: cuando se produce un fallo de página, hay que encontrar una página que no esté en el conjunto de trabajo y desalojarla. Para implementar este algoritmo, necesitamos una forma precisa de determinar qué páginas están en el conjunto de trabajo. Por definición, el conjunto de trabajo es el conjunto de páginas utilizadas en las k referencias de memoria más recientes (algunos autores utilizan las k referencias de página más recientes, pero la elección es arbitraria).  Para implementar cualquier algoritmo de conjunto de trabajo, debe elegirse de antemano algún valor de k.  Entonces, después de cada referencia de memoria, se determina de forma única el conjunto de páginas utilizadas por las k referencias de memoria más recientes.

Por supuesto, tener una definición operativa del conjunto de trabajo no significa que haya una forma eficiente de calcularlo durante la ejecución del programa. Se podría imaginar un registro de desplazamiento de longitud k, con cada referencia de memoria desplazando el registro una posición a la izquierda e insertando el número de página referenciado más recientemente a la derecha. El conjunto de todos los k números de página en el registro de desplazamiento sería el conjunto de trabajo.En teoría, en un fallo de página, el contenido del registro de desplazamiento podría ser leído y ordenado. Las páginas duplicadas podrían eliminarse.  El resultado sería el conjunto de trabajo. Sin embargo, mantener el registro de desplazamiento y procesarlo en un fallo de página sería prohibitivamente caro, por lo que esta técnica nunca se utiliza.

En su lugar, se utilizan varias aproximaciones. Una aproximación comúnmente utilizada es abandonar la idea de contar hacia atrás k referencias de memoria y utilizar en su lugar el tiempo de ejecución. Por ejemplo, en lugar de definir el conjunto de trabajo como las páginas utilizadas durante los 10 millones de referencias de memoria anteriores, podemos definirlo como el conjunto de páginas utilizadas durante los últimos 100 mseg de tiempo de ejecución. En la práctica, esta definición es igual de buena y mucho más fácil de utilizar. Tenga en cuenta que, para cada proceso, sólo cuenta su propio tiempo de ejecución. Así, si un proceso comienza a ejecutarse en el tiempo T y ha tenido 40 mseg de tiempo de CPU en el tiempo real T + 100 mseg, para propósitos del conjunto de trabajo su tiempo es de 40 mseg. La cantidad de tiempo de CPU que un proceso ha utilizado realmente desde que comenzó se llama a menudo su **current virtual time**. Con esta aproximación, el conjunto de trabajo de un proceso es el conjunto de páginas que ha referenciado durante los últimos τ segundos de tiempo virtual.

Veamos ahora un algoritmo de sustitución de páginas basado en el working set. La idea básica es encontrar una página que no está en el conjunto de trabajo y desalojarla. En la Fig. 3-19 vemos una porción de una tabla de páginas para alguna máquina. Debido a que sólo las páginas localizadas en memoria son consideradas como candidatas para ser desalojadas, las páginas que están ausentes de la memoria son ignoradas por este algoritmo. Cada entrada contiene (al menos) dos elementos clave de información: la hora (aproximada) en que la página fue usada por última vez y el bit R (Referenced). Un rectángulo blanco vacío simboliza los demás campos no necesarios para este algoritmo, como el número de page frame, los bits de protección y el bit M (Modificado).

![figure3-19](https://github.com/gabo52/SistemasOperativos/blob/main/figures/Chapter3/figure3-19.png?raw=true)

El algoritmo funciona así. Se supone que el hardware establece los bits R y M, como se ha comentado anteriormente. Del mismo modo, se supone que una interrupción periódica del reloj hace que se ejecute un software que borra el bit Referenced en cada tick del reloj. En cada fallo de página, se escanea la tabla de páginas para buscar una página adecuada para desalojar.

A medida que se procesa cada entrada, se examina el bit R.  Si es 1, la hora virtual actual se escribe en el campo Hora de último uso de la tabla de páginas, indicando que la página estaba en uso en el momento en que se produjo el fallo. Dado que la página ha sido referenciada durante la actual marca de reloj, está claramente en el conjunto de trabajo y no es candidata a ser eliminada (se supone que τ abarca múltiples marcas de reloj).

Si R es 0, la página no ha sido referenciada durante el tiempo virtual actual y puede ser candidata a ser eliminada.  Para ver si se debe eliminar o no, se calcula su edad (el tiempo virtual actual menos su Hora de último uso) y se compara con τ. Si la edad es mayor que τ, la página ya no está en el conjunto de trabajo y la nueva página la sustituye. 

Sin embargo, si R es 0 pero la edad es menor o igual que τ, la página sigue en el conjunto de trabajo. La página se salva temporalmente, pero se anota la página con mayor antigüedad (menor valor de Tiempo de último uso).  Si se escanea toda la tabla sin encontrar ningún candidato a desalojar, significa que todas las páginas están en el conjunto de trabajo. En ese caso, si se encuentran una o varias páginas con R = 0, se expulsa la que tenga la mayor antigüedad.  En el peor de los casos, todas las páginas han sido referenciadas durante el tic del reloj actual (y por tanto todas tienen R = 1), por lo que se elige una al azar para ser desalojada, preferiblemente una página limpia, si existe.


## 3.4.9 The WSClock Page Replacement Algorithm


## 3.4.10 Summary of Page Replacement Algorithms