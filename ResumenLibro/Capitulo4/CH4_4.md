# 4.4 FILE-SYSTEM MANAGEMENT AND OPTIMIZATION

Hacer que el sistema de archivos funcione es una cosa; hacer que funcione de forma eficiente y robusta en la vida real es algo muy distinto.  En las secciones siguientes veremos algunos de los problemas que plantea la gestión de discos.

## 4.4.1 Disk-Space Management

Los archivos se almacenan normalmente en disco, por lo que la gestión del espacio en disco es una de las principales preocupaciones de los diseñadores de sistemas de archivos. Existen dos estrategias generales para almacenar un archivo de n bytes: se asignan n bytes consecutivos de espacio en disco, o el archivo se divide en un número de bloques (no necesariamente) contiguos. Como hemos visto, el almacenamiento de un archivo como una secuencia contigua de bytes tiene el problema obvio de que si un archivo crece, es posible que haya que moverlo en el disco. El mismo problema se aplica a los segmentos en memoria, excepto que mover un segmento en memoria es una operación relativamente rápida en comparación con mover un archivo de una posición de disco a otra. Por este motivo, casi todos los sistemas de archivos dividen los archivos en bloques de tamaño fijo que no tienen por qué ser adyacentes.

### Block Size

Una vez que se ha decidido almacenar los archivos en bloques de tamaño fijo, surge la pregunta de qué tamaño debe tener el bloque. Dada la forma en que están organizados los discos, el sector, la pista y el cilindro son candidatos obvios para la unidad de asignación (aunque todos ellos dependen del dispositivo, lo cual es un inconveniente). En un sistema de paginación, el tamaño de la página también es un contendiente importante.

Un tamaño de bloque grande significa que cada archivo, aunque sea de 1 byte, ocupa un cilindro entero. Por otro lado, un tamaño de bloque pequeño significa que la mayoría de los archivos abarcarán varios bloques y, por tanto, necesitarán varias búsquedas y retrasos de rotación para leerlos, lo que reduce el rendimiento. Por tanto, si la unidad de asignación es demasiado grande, desperdiciamos espacio; si es demasiado pequeña, desperdiciamos tiempo.

Un tamaño de bloque grande significa que cada archivo, aunque sea de 1 byte, ocupa un cilindro entero. Por otro lado, un tamaño de bloque pequeño significa que la mayoría de los archivos abarcarán varios bloques y, por tanto, necesitarán varias búsquedas y retrasos de rotación para leerlos, lo que reduce el rendimiento. Por tanto, si la unidad de asignación es demasiado grande, desperdiciamos espacio; si es demasiado pequeña, desperdiciamos tiempo.

Para hacer una buena elección es necesario disponer de información sobre la distribución del tamaño de los archivos.  Tanenbaum et al. (2006) estudiaron la distribución del tamaño de los archivos en el Departamento de Informática de una gran universidad de investigación (la VU) en 1984 y de nuevo en 2005, así como en un servidor web comercial que albergaba un sitio web político (www.electoral-vote.com).  Los resultados se muestran en la Fig. 4-20, donde para cada tamaño de archivo de potencia de dos, se enumera el porcentaje de todos los archivos menores o iguales para cada uno de los tres conjuntos de datos. Por ejemplo, en 2005, el 59.13% de todos los archivos de la VU tenían un tamaño igual o inferior a 4 KB y el 90,84% de todos los archivos tenían un tamaño igual o inferior a 64 KB. El tamaño medio de los archivos era de 2.475 bytes. Puede que a algunas personas les sorprenda este pequeño tamaño.

![figure4-20](https://github.com/gabo52/SistemasOperativos/blob/main/figures/Chapter4/figure4-20.png?raw=true)

¿Qué conclusiones podemos sacar de estos datos? Por un lado, con un tamaño de bloque de 1 KB, sólo entre el 30 y el 50% de todos los archivos caben en un solo bloque, mientras que con un bloque de 4 KB, el porcentaje de archivos que caben en un bloque sube hasta el 60-70%. Otros datos del artículo muestran que con un bloque de 4 KB, el 93% de los bloques de disco son utilizados por el 10% de los archivos más grandes. Esto significa que perder algo de espacio al final de cada archivo pequeño apenas importa porque el disco está lleno por un pequeño número de archivos grandes (vídeos) y la cantidad total de espacio ocupado por los archivos pequeños apenas importa. Incluso duplicando el espacio que ocupa el 90% de los archivos más pequeños apenas se notaría.

Por otro lado, utilizar un bloque pequeño significa que cada archivo estará formado por muchos bloques. Normalmente, la lectura de cada bloque requiere una búsqueda y un retardo de rotación (excepto en un disco de estado sólido), por lo que la lectura de un archivo formado por muchos bloques pequeños será lenta.

Como ejemplo, consideremos un disco con 1 MB por pista, un tiempo de rotación de 8,33 mseg y un tiempo medio de búsqueda de 5 mseg. El tiempo en milisegundos para leer un bloque de k bytes es la suma de los tiempos de búsqueda, rotación y transferencia: 

    5 + 4. 165 + (k/1000000) × 8. 33

La curva discontinua de la Fig. 4-21 muestra la tasa de datos de un disco de este tipo en función del tamaño del bloque. Para calcular la eficiencia de espacio, tenemos que hacer una suposición sobre el tamaño medio de los archivos. Para simplificar, supongamos que todos los archivos son de 4 KB. Aunque este número es ligeramente mayor que los datos medidos en la VU, los estudiantes probablemente tienen más archivos pequeños de los que estarían presentes en un centro de datos corporativo, por lo que podría ser una mejor suposición en general. La curva continua de la Fig. 4-21 muestra la eficiencia de espacio en función del tamaño de bloque

Las dos curvas pueden entenderse de la siguiente manera. El tiempo de acceso a un bloque está totalmente dominado por el tiempo de búsqueda y el retardo de rotación, por lo que, dado que va a costar 9 mseg acceder a un bloque, cuantos más datos se obtengan, mejor.

![figure4-21](https://github.com/gabo52/SistemasOperativos/blob/main/figures/Chapter4/figure4-21.png?raw=true)

De ahí que la velocidad de transmisión de datos aumente casi linealmente con el tamaño del bloque (hasta que las transferencias duran tanto que el tiempo de transferencia empieza a importar).

Consideremos ahora la eficiencia espacial. Con archivos de 4 KB y bloques de 1, 2 o 4 KB, los archivos utilizan 4, 2 y 1 bloque, respectivamente, sin desperdicio. Con un bloque de 8 KB y archivos de 4 KB, la eficiencia espacial desciende al 50%, y con un bloque de 16 KB baja al 25%. En realidad, pocos archivos son un múltiplo exacto del tamaño del bloque de disco, por lo que siempre se desperdicia algo de espacio en el último bloque de un archivo.

Lo que muestra el gráfico, sin embargo, es que el rendimiento y la utilización del espacio están intrínsecamente en conflicto. Los bloques pequeños son malos para el rendimiento, pero buenos para la utilización del espacio en disco. Para estos datos, no existe un compromiso razonable. El tamaño más cercano al cruce de las dos curvas es 64 KB, pero la velocidad de transmisión de datos es de sólo 6,6 MB/s y la eficiencia del espacio es de aproximadamente el 7%, ninguna de las cuales es muy buena. Históricamente, los sistemas de archivos han elegido tamaños comprendidos entre 1 y 4 KB, pero ahora que los discos superan 1 TB, quizá sea mejor aumentar el tamaño de bloque a 64 KB y aceptar el espacio de disco desperdiciado. El espacio en disco ya no escasea.

En un experimento para ver si el uso de archivos de Windows NT era sensiblemente diferente del uso de archivos de UNIX, Vogels realizó mediciones de archivos en la Universidad de Cornell (Vogels, 1999). Observó que el uso de archivos en NT es más complicado que en UNIX. Escribió:

*When we type a few characters in the Notepad text editor, saving this to afile will trigger 26 system calls, including 3 failed open attempts, 1 fileoverwrite and 4 additional open and close sequences.*

Sin embargo, Vogels observó un tamaño medio (ponderado por el uso) de los archivos sólo leídos de 1 KB, de los archivos sólo escritos de 2,3 KB y de los archivos leídos y escritos de 4,2 KB. Dadas las diferentes técnicas de medición de los conjuntos de datos y el año, estos resultados son ciertamente compatibles con los de la VU.

### Keeping Track of Free Blocks

Una vez elegido el tamaño de bloque, la siguiente cuestión es cómo llevar la cuenta de los bloques libres. Dos métodos son ampliamente usados, como se muestra en la Fig. 4-22. El primero consiste en utilizar una lista enlazada de bloques de disco, en la que cada bloque contiene tantos números de bloque de disco libres como quepan. Con un bloque de 1 KB y un número de bloque de disco de 32 bits, cada bloque de la lista libre contiene los números de 255 bloques libres. (Considere un disco de 1 TB, que tiene alrededor de 1.000 millones de bloques de disco. Para almacenar todas estas direcciones a 255 por bloque se necesitan unos 4 millones de bloques. Generalmente, los bloques libres se utilizan para mantener la lista libre, por lo que el almacenamiento es esencialmente gratuito.

![figure4-22](https://github.com/gabo52/SistemasOperativos/blob/main/figures/Chapter4/figure4-22.png?raw=true)

La otra técnica de gestión del espacio libre es el mapa de bits. Un disco con n bloques requiere un mapa de bits con n bits. Los bloques libres se representan con 1s en el mapa, los bloques asignados con 0s (o viceversa).  Para nuestro disco de ejemplo de 1 TB, necesitamos 1.000 millones de bits para el mapa, lo que requiere almacenar unos 130.000 bloques de 1 KB. No es sorprendente que el mapa de bits requiera menos espacio, ya que utiliza 1 bit por bloque, frente a los 32 bits del modelo de lista enlazada. Sólo si el disco está casi lleno (es decir, tiene pocos bloques libres), el esquema de listas enlazadas necesitará menos bloques que el mapa de bits.

Si los bloques libres tienden a venir en largas series de bloques consecutivos, el sistema de lista libre puede modificarse para llevar la cuenta de series de bloques en lugar de bloques individuales. Se puede asociar a cada bloque un contador de 8, 16 o 32 bits que indique el número de bloques libres consecutivos. En el mejor de los casos, un disco básicamente vacío podría representarse con dos números: la dirección del primer bloque libre seguida del contador de bloques libres. En cambio, si el disco está muy fragmentado, el seguimiento de las ejecuciones es menos eficaz que el de los bloques individuales, ya que no sólo hay que almacenar la dirección, sino también el contador.

Esta cuestión ilustra un problema que suelen tener los diseñadores de sistemas operativos. Hay múltiples estructuras de datos y algoritmos que pueden utilizarse para resolver un problema, pero elegir el mejor requiere datos que los diseñadores no tienen y no tendrán hasta que el sistema se despliegue y se utilice intensamente. E incluso entonces, los datos pueden no estar disponibles.  Por ejemplo, nuestras propias mediciones del tamaño de los archivos en la VU en 1984 y 1995, los datos del sitio web y los datos de Cornell son sólo cuatro muestras. Aunque es mucho mejor que nada, no tenemos ni idea de si también son representativos de los ordenadores domésticos, los ordenadores de empresa, los ordenadores gubernamentales y otros. Con un poco de esfuerzo podríamos haber conseguido un par de muestras de otros tipos de ordenadores, pero incluso así sería absurdo extrapolarlos a todos los ordenadores del tipo medido.

Volviendo por un momento al método de la lista libre, sólo es necesario mantener un bloque de punteros en la memoria principal. Cuando se crea un archivo, los bloques necesarios se toman del bloque de punteros. Cuando se agota, se lee un nuevo bloque de punteros del disco. Del mismo modo, cuando se elimina un archivo, se liberan sus bloques y se añaden al bloque de punteros de la memoria principal. Cuando este bloque se llena, se escribe en el disco.

Bajo ciertas circunstancias, este método conduce a E/S de disco innecesarias. Considere la situación de la Fig. 4-23(a), en la que el bloque de punteros en memoria sólo tiene espacio para dos entradas más. Si se libera un fichero de tres bloques, el bloque de punteros se desborda y tiene que escribirse en disco, lo que lleva a la situación de la Fig. 4-23(b).  Si ahora se escribe un fichero de tres bloques, hay que volver a leer el bloque completo de punteros, lo que nos lleva de nuevo a la Fig. 4-23(a).  Si el archivo de tres bloques que se acaba de escribir era un archivo temporal, cuando se libera, se necesita otra escritura en disco para escribir el bloque completo de punteros de nuevo en el disco. En resumen, cuando el bloque de punteros está casi vacío, una serie de archivos temporales de corta duración pueden causar muchos I/O de disco.

Un enfoque alternativo que evita la mayor parte de esta E/S de disco es dividir el bloque completo de punteros. Así, en lugar de pasar de la Fig. 4-23(a) a la Fig. 4-23(b), pasamos de la Fig. 4-23(a) a la Fig. 4-23(c) cuando se liberan tres bloques. Ahora el sistema puede manejar una serie de archivos temporales sin hacer ninguna E/S de disco. Si el bloque en memoria se llena, se escribe en el disco, y se lee el bloque medio lleno del disco. La idea aquí es mantener la mayoría de los bloques de punteros en el disco llenos (para minimizar el uso del disco), pero mantener el que está en memoria medio lleno, para que pueda manejar tanto la creación como la eliminación de archivos sin E/S de disco en la lista libre.
# Preguntas

¿Qué pros y contras tienen una página grande y pequeña?

¿Cómo funcina el disk space utilization y el data rate(Mb/sec) con distintos tamaños de página.

¿Cuál es el tamaño de página recomendado y cómo afectan los tamaños de página?

¿Cómo se mantiene el registro de los discos libres con una lista enlazada?
¿Cómo se mantiene el registro de los discos libres con la otra estrategia?

