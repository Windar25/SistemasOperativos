#  4.3 FILE SYSTEM IMPLEMENTATION

Ahora es el momento de pasar de la visión del usuario del sistema de archivos a la visión del implementador. A los usuarios les preocupa cómo se nombran los archivos, qué operaciones se permiten sobre ellos, qué aspecto tiene el árbol de directorios y otras cuestiones similares relacionadas con la interfaz. A los implementadores les interesa cómo se almacenan los archivos y directorios, cómo se gestiona el espacio en disco y cómo hacer que todo funcione de forma eficiente y fiable. En las secciones siguientes examinaremos algunas de estas áreas para ver cuáles son los problemas y las desventajas.

# 4.3.1 File-System Layout

Los sistemas de archivos se almacenan en discos. La mayoría de los discos pueden dividirse en una o más particiones, con sistemas de archivos independientes en cada partición. El sector 0 del disco se denomina **MBR (Master Boot Record)** y se utiliza para arrancar el ordenador. Esta tabla indica las direcciones inicial y final de cada partición. Una de las particiones de la tabla está marcada como activa. Cuando se arranca el ordenador, la BIOS lee y ejecuta el MBR. Lo primero que hace el programa MBR es localizar la partición activa, leer su primer bloque, que se llama  **boot block**, y ejecutarlo. El programa en el bloque de arranque carga el sistema operativo contenido en esa partición. Por uniformidad, la partición comienza con un **boot block**, aunque no contenga un sistema operativo de arranque. Además, podría contener uno en el futuro. Aparte de comenzar con un bloque de arranque, la disposición de una partición de disco varía mucho de un sistema de archivos a otro. A menudo, el sistema de archivos contendrá algunos de los elementos que se muestran en la Fig. 4-9. El primero es el **superblock**. Contiene todos los parámetros clave sobre el sistema de ficheros y se lee en memoria cuando se arranca el ordenador o se toca el sistema de ficheros por primera vez. La información típica en el superblock incluye un número mágico para identificar el tipo de sistema de archivos, el número de bloques en el sistema de archivos y otra información administrativa clave.

[figure4.9]

A continuación puede venir la información sobre los bloques libres en el sistema de archivos, por ejemplo, en forma de mapbit o lista de punteros. A continuación, pueden aparecer los i nodos, un array de data structure, una por cada archivo, que lo describen todo del archivo. Después puede venir el root directory, que contiene la parte superior del árbol del file system. Por último, el resto del disco contiene todos los demás directorios y archivos.

## 4.3.2 Implementing Files

Probablemente, el problema más importante a la hora de almacenar archivos es saber qué bloques de disco corresponden a cada file. En los distintos sistemas operativos se utilizan varios métodos. En esta sección examinaremos algunos de ellos.

### Contiguos Allocation

El esquema de asignación más sencillo consiste en almacenar cada archivo como una serie contigua de bloques de disco. Así, en un disco con bloques de 1 KB, a un file de 50 KB se le asignarían 50 bloques consecutivos. Con bloques de 2 KB, se le asignarían 25 bloques consecutivos. Vemos un ejemplo de asignación de almacenamiento contiguo en la Fig. 4-10(a).  Aquí se muestran los primeros 40 bloques de disco, comenzando con el bloque 0 a la izquierda. Inicialmente, el disco estaba vacío. Luego un archivo A, de cuatro bloques de longitud, fue escrito en el disco comenzando por el principio (bloque 0). Después se escribió un archivo de seis bloques, B, empezando justo después del final del archivo A.

Tenga en cuenta que cada archivo comienza al principio de un nuevo bloque, de modo que si el archivo A tenía realmente 3½ bloques, se desperdicia algo de espacio al final del último bloque. En la figura se muestra un total de siete files, cada uno de los cuales comienza en el bloque siguiente al final del anterior. El sombreado se utiliza sólo para que sea más fácil distinguir los archivos. No tiene ninguna importancia real en términos de almacenamiento.

[figure4-10]

La asignación continua de espacio en disco tiene dos ventajas significativas. En primer lugar, es fácil de implementar, ya que para saber dónde están los bloques de un archivo sólo hay que recordar dos números: la dirección de disco del primer bloque y el número de bloques del archivo. Dado el número del primer bloque, el número de cualquier otro bloque se puede encontrar mediante una simple suma.

En segundo lugar, el rendimiento de lectura es excelente, ya que todo el archivo puede leerse desde el disco en una sola operación.  Sólo es necesaria una búsqueda (hasta el primer bloque). A partir de ese momento, ya no se necesitan más búsquedas ni retardos de rotación, por lo que los datos llegan con todo el ancho de banda del disco. Por lo tanto, la asignación continua es fácil de implementar y tiene un alto rendimiento.

Desafortunadamente, la asignación contigua también tiene un grave inconveniente: con el paso del tiempo, el disco se fragmenta. Para ver cómo ocurre esto, examine la Fig. 4-10(b).  Aquí dos ficheros, D y F, han sido eliminados. Cuando se vuelve a mover un fichero, sus bloques se liberan de forma natural, dejando una serie de bloques libres en el disco. 

Desafortunadamente, la asignación contigua también tiene un grave inconveniente: con el paso del tiempo, el disco se fragmenta. Para ver cómo ocurre esto, examine la Fig. 4-10(b).  Aquí dos ficheros, D y F, han sido eliminados. Cuando se vuelve a mover un fichero, sus bloques se liberan de forma natural, dejando una serie de bloques libres en el disco. El disco no se compacta en el momento para eliminar el agujero, ya que eso implicaría copiar todos los bloques que siguen al agujero, potencialmente millones de bloques, lo que llevaría horas o incluso días con discos grandes. Como resultado, el disco se compone en última instancia de files y holes, como se ilustra en la figura.

Inicialmente, esta fragmentación no es un problema, ya que cada nuevo file puede escribirse al final del disco, a continuación del anterior. Sin embargo, con el tiempo el disco se llenará y será necesario compactarlo, lo que es prohibitivamente caro, o reutilizar el espacio libre en los huecos. Reutilizar el espacio requiere mantener una lista de huecos, lo que es factible. Sin embargo, cuando se va a crear un nuevo archivo, es necesario conocer su tamaño final para elegir un agujero del tamaño correcto en el que colocarlo.

Imagine las consecuencias de un diseño así. El usuario inicia un procesador de textos para crear un documento. Lo primero que pregunta el programa es cuántos bytes tendrá el documento final. La pregunta debe responderse o el programa no continuará.  Si al final el número dado resulta ser demasiado pequeño, el programa tiene que terminar prematuramente porque el hueco del disco está lleno y no hay sitio para meter el resto del archivo.  Si el usuario trata de evitar este problema dando un número irrealmente grande como tamaño final, por ejemplo, 1 GB, el editor puede ser incapaz de encontrar un agujero tan grande y anunciar que el archivo no se puede crear. Por supuesto, el usuario sería libre de iniciar el programa de nuevo y decir 500 MB esta vez, y así sucesivamente hasta que se encontró un agujero adecuado. Aun así, no es probable que este esquema haga felices a los usuarios.

Sin embargo, hay una situación en la que la asignación contigua es factible y, de hecho, todavía se utiliza: en los CD-ROM.  En este caso, todos los tamaños de archivo se conocen de antemano y nunca cambiarán durante el uso posterior del sistema de archivos del CD-ROM. 

La situación con los DVD es un poco más complicada. En principio, una película de 90 minutos podría codificarse como un único archivo de unos 4,5 GB de longitud, pero el file system utilizado, UDF (Universal Disk Format), utiliza un número de 30 bits para representar la longitud de los archivos, lo que los limita a 1 GB. En consecuencia, las películas en DVD suelen almacenarse en tres o cuatro archivos de 1 GB, cada uno de ellos contiguo. Estas partes físicas de un único archivo lógico (la película) se denominan **extents**.

Como mencionamos en el Capítulo 1, la historia se repite a menudo en informática a medida que aparecen nuevas generaciones de tecnología. La asignación contigua se utilizaba en los sistemas de archivos de disco magnético hace años debido a su simplicidad y alto rendimiento (la facilidad de uso no contaba mucho entonces). Luego se abandonó la idea debido a la molestia de tener que especificar el tamaño final del archivo en el momento de crearlo. Pero con la llegada de los CD-ROM, DVD, Blu-ray y otros soportes ópticos de una sola escritura, los archivos contiguos volvieron a ser una buena idea.  Por eso es importante estudiar los sistemas antiguos y las ideas que eran conceptualmente limpias y sencillas, porque pueden aplicarse a sistemas futuros de forma sorprendente.

### Linked-List Allocation

El segundo método para almacenar ficheros es mantener cada uno como una lista enlazada de bloques de disco, como se muestra en la Fig. 4-11.  La primera palabra de cada bloque se utiliza como puntero al siguiente. El resto del bloque es para datos.

[figure4-11]

A diferencia de la asignación contigua, en este método se pueden utilizar todos los bloques de disco. No se pierde espacio por la fragmentación del disco (salvo la fragmentación interna del último bloque).  Además, basta con que la entrada del directorio almacene la dirección de disco del primer bloque. El resto puede encontrarse a partir de ahí. Por otra parte, aunque la lectura secuencial de un fichero es sencilla, el acceso aleatorio es extremadamente lento.  Para llegar al bloque n, el sistema operativo tiene que empezar por el principio y leer los n - 1 bloques anteriores, de uno en uno. Está claro que hacer tantas lecturas será terriblemente lento.

Además, la cantidad de datos almacenados en un bloque ya no es una potencia de dos porque el puntero ocupa unos pocos bytes. Aunque no es fatal, tener un tamaño peculiar es menos eficiente porque muchos programas leen y escriben en bloques cuyo tamaño es una potencia de dos. Con los primeros bytes de cada bloque ocupados por un puntero al siguiente bloque, las lecturas del tamaño del bloque completo requieren adquirir y concatenar información de dos bloques de disco, lo que genera una sobrecarga adicional debido a la copia.

## Linked-List Allocation Using a Table in Memory

Ambas desventajas de la asignación de listas enlazadas pueden eliminarse tomando la palabra puntero de cada bloque de disco y poniéndola en una tabla en memoria. La Figura 4-12 muestra el aspecto de la tabla para el ejemplo de la Fig. 4-11. En ambas figuras, tenemos dos archivos. El archivo A usa los bloques de disco 4, 7, 2, 10 y 12, en ese orden, y el archivo B usa los bloques de disco 6, 3, 11 y 14, en ese orden. Usando la tabla de la Fig. 4-12, podemos empezar por el bloque 4 y seguir la cadena hasta el final. Lo mismo se puede hacer empezando por el bloque 6. Ambas cadenas terminan con un marcador especial (por ejemplo, -1) que no es un número de bloque válido. Una tabla de este tipo en la memoria principal se denomina FAT (File Allocation Table).

[figure4-12]

Con esta organización, todo el bloque está disponible para los datos. Además, el random access es mucho más fácil. Aunque todavía hay que seguir la cadena para encontrar un desplazamiento determinado dentro del archivo, la cadena está completamente en memoria, por lo que se puede seguir sin hacer ninguna referencia al disco. Al igual que en el método anterior, basta con que la entrada del directorio mantenga un único número entero (el número de bloque inicial) para poder localizar todos los bloques, independientemente de lo grande que sea el fichero. 

La principal desventaja de este método es que toda la tabla debe estar en memoria todo el tiempo para que funcione. Con un disco de 1 TB y un tamaño de bloque de 1 KB, la tabla necesita 1.000 millones de entradas, una por cada uno de los 1.000 millones de bloques de disco. Cada entrada debe tener un mínimo de 3 bytes. Para acelerar la búsqueda, deben ser de 4 bytes. Así, la tabla ocupará 3 GB o 2,4 GB de memoria principal todo el tiempo, dependiendo de si el sistema está optimizado para el espacio o el tiempo. No es muy práctico. Está claro que la idea de la FAT no se adapta bien a los discos grandes. Fue el file system original de MS-DOS y, sin embargo, sigue siendo totalmente compatible con todas las versiones de Windows.

### I-nodes

Nuestro último método para llevar la cuenta de qué bloques pertenecen a qué archivo es asociar a cada archivo una estructura de datos llamada nodo-i (nodo-índice), que enumera los atributos y las direcciones de disco de los bloques del archivo.  En la Fig. 4-13 se muestra un ejemplo sencillo.  A partir del i-node, es posible encontrar todos los bloques del archivo.

La gran ventaja de este esquema sobre los ficheros enlazados que utilizan una tabla en memoria es que el nodo-i sólo necesita estar en memoria cuando el fichero correspondiente está abierto. Si cada nodo-i ocupa n bytes y puede haber un máximo de k ficheros abiertos a la vez, la memoria total ocupada por la matriz que contiene los i-nodos de los ficheros abiertos es de sólo kn bytes. Sólo es necesario reservar este espacio por adelantado.

[figure4-13]

Este array suele ser mucho más pequeña que el espacio ocupado por la tabla de archivos descrita en la sección anterior. La razón es sencilla. La tabla que contiene la linked list de todos los bloques del disco tiene un tamaño proporcional al del propio disco. Si el disco tiene n bloques, la tabla necesita n entradas.  A medida que los discos aumentan de tamaño, la tabla crece linealmente con ellos. Por el contrario, el esquema i-node requiere una matriz en memoria cuyo tamaño es proporcional al número máximo de archivos que pueden estar abiertos a la vez. No importa si el disco tiene 100 GB, 1.000 GB o 10.000 GB. 

Un problema con los i-nodos es que si cada uno tiene espacio para un número fijo de direcciones de disco, ¿qué pasa cuando un archivo crece más allá de este límite? Una solución es reservar la última dirección de disco no para un bloque de datos, sino para la dirección de un bloque que contenga más direcciones de bloque de disco, como se muestra en la Fig. 4-13.  Aún más avanzado sería dos o más bloques de este tipo que contengan direcciones de disco o incluso bloques de disco que apunten a otros bloques de disco llenos de direcciones. Volveremos a los nodos-i cuando estudiemos UNIX en el Cap. 10. De forma similar, el sistema de ficheros NTFS de Windows utiliza una idea parecida, sólo que con i-nodos más grandes que también pueden contener ficheros pequeños.

## 4.3.3 Implementing Directories

Antes de poder leer un file, hay que abrirlo. Cuando se abre un file, el sistema operativo utiliza el nombre de la ruta facilitado por el usuario para localizar la entrada del directory en el disco. La entrada del directory proporciona la información necesaria para encontrar los bloques del disco.  Dependiendo del sistema, esta información puede ser la dirección de disco de todo el archivo (con contiguos allocation), el número del primer bloque (ambos esquemas de linked-list) o el número del nodo i. En todos los casos, la función principal del sistema de directorios es asignar del nombre ASCII del file a la información necesaria para localizar los datos.

Una cuestión estrechamente relacionada es dónde deben almacenarse los atributos. Cada sistema de ficheros mantiene varios atributos de fichero, como el propietario de cada fichero y la hora de creación, y deben almacenarse en algún sitio. Una posibilidad obvia es almacenarlos directamente en la entrada del directorio. Algunos sistemas hacen precisamente eso. Esta opción se muestra en la Fig. 4-14(a).  En este diseño simple, un directorio consiste en una lista de entradas de tamaño fijo, una por fichero, que contiene un nombre de fichero (de longitud fija), una estructura de los atributos del fichero, y una o más direcciones de disco (hasta un máximo) que indican dónde están los bloques de disco.

[figure-4-14]

Para los sistemas que utilizan nodos-i, otra posibilidad de almacenar los atributos es en los nodos-i, en lugar de en las entradas de directorio. En ese caso, la entrada del directorio puede ser más corta: sólo un nombre de archivo y un número de nodo-i. Este enfoque se ilustra en la Fig. 4-14(b). Como veremos más adelante, este método tiene algunas ventajas sobre ponerlos en la entrada del directorio.

En MS-DOS, los archivos tienen un nombre base de 1 a 8 caracteres y una extensión opcional de 1 a 3 caracteres.  En la versión 7 de UNIX, los nombres de archivo tenían entre 1 y 14 caracteres, incluidas las extensiones. Sin embargo, casi todos los sistemas operativos modernos admiten nombres de archivo más largos y de longitud variable. ¿Cómo se pueden implementar?

El enfoque más simple es establecer un límite en la longitud del nombre del archivo, típicamente 255 caracteres, y luego usar uno de los diseños de la Fig. 4-14 con 255 caracteres reservados para cada nombre de archivo. Este enfoque es simple, pero desperdicia una gran cantidad de espacio de directorio, ya que pocos archivos tienen nombres tan largos. Por razones de eficiencia, es deseable una estructura diferente.

Una alternativa es renunciar a la idea de que todas las entradas de directorio tienen el mismo tamaño.Con este método, cada entrada de directorio contiene una parte fija, que suele comenzar con la longitud de la entrada, y a la que siguen datos con un formato fijo, que suelen incluir el propietario, la hora de creación, información de protección y otros atributos.A esta cabecera de longitud fija le sigue el nombre real del fichero, por largo que sea, como se muestra en la Fig. 4-15(a) en formato big-endian (por ejemplo, SPARC).  En este ejemplo tenemos tres ficheros, proyecto-presupuesto, personal y foo. Cada nombre de fichero está terminado por un carácter especial (normalmente 0), que está representado en la figura por una caja con una cruz. Para permitir que cada entrada de directorio comience en un límite de palabra, cada nombre de fichero se rellena con un número entero de palabras, que se muestran en la figura mediante recuadros sombreados.

[figure4.15]

Una desventaja de este método es que cuando se elimina un archivo, se introduce un hueco de tamaño variable en el directorio en el que puede que no quepa el siguiente archivo que se introduzca.

Este problema es esencialmente el mismo que vimos con los archivos de disco contiguos, sólo que ahora compactar el directorio es factible porque está enteramente en memoria. Otro problema es que una sola entrada de directorio puede abarcar varias páginas, por lo que puede producirse un fallo de página al leer un nombre de archivo.

Otra forma de manejar nombres de longitud variable es hacer que las propias entradas del directorio sean todas de longitud fija y mantener los nombres de fichero juntos en un montón al final del directorio, como se muestra en la Fig. 4-15(b).  Este método tiene la ventaja de que cuando se elimina una entrada, el siguiente fichero introducido siempre cabe allí. Por supuesto, el montón debe ser gestionado y los fallos de página pueden ocurrir mientras se procesan los nombres de los ficheros. Una pequeña ventaja aquí es que ya no hay necesidad real de que los nombres de fichero comiencen en los límites de palabra, por lo que no se necesitan caracteres de relleno después de los nombres de fichero en la Fig. 4-15(b)como en la Fig. 4-15(a).

En todos los diseños realizados hasta ahora, los directorios se buscan linealmente de principio a fin cuando hay que buscar un nombre de archivo. Para directorios muy largos, la búsqueda lineal puede ser lenta.  Una forma de acelerar la búsqueda es utilizar una tabla hash en cada directorio. Digamos que el tamaño de la tabla es n. Para introducir el nombre de un fichero, el nombre se convierte en un valor comprendido entre 0 y n - 1, por ejemplo, dividiéndolo por n y tomando el resto. También se pueden sumar las palabras que componen el nombre del fichero y dividir esta cantidad por n, o algo similar.

En cualquier caso, se comprueba la entrada de la tabla correspondiente al código hash. Si no se utiliza, se coloca un puntero a la entrada del archivo. Si esa ranura ya está en uso, se construye una lista enlazada, encabezada por la entrada de la tabla y recorriendo todas las entradas con el mismo valor hash.

La búsqueda de un archivo sigue el mismo procedimiento. El nombre del archivo se convierte en hash para seleccionar una entrada de la tabla hash. Se comprueban todas las entradas de la cadena encabezadas por esa ranura para ver si el nombre del archivo está presente. Si el nombre no está en la cadena, el fichero no está presente en el directorio.

El uso de una tabla hash tiene la ventaja de una búsqueda mucho más rápida, pero la desventaja de una administración más compleja.  Sólo es un candidato serio en sistemas en los que se espera que los directorios contengan habitualmente cientos o miles de archivos.

Otra forma de acelerar la búsqueda en directorios grandes es almacenar en caché los resultados de las búsquedas. Antes de iniciar una búsqueda, se comprueba si el nombre del fichero está en la caché. En caso afirmativo, se puede localizar inmediatamente. Por supuesto, el almacenamiento en caché sólo funciona si la mayoría de las búsquedas se realizan en un número relativamente pequeño de archivos.

## 4.3.4 Shared Files

Cuando varios usuarios trabajan juntos en un proyecto, a menudo necesitan compartir archivos.  Como resultado, a menudo es conveniente que un fichero compartido aparezca simultáneamente en diferentes directorios pertenecientes a diferentes usuarios. La Figura 4-16 muestra de nuevo el sistema de archivos de la Fig. 4-7, sólo que ahora uno de los archivos de C también está presente en uno de los directorios de B. La conexión entre el directorio de B y el directorio de C es la misma. La conexión entre el directorio de B y el archivo compartido se llama **link**. El propio sistema de ficheros es ahora un **Directed Acyclic Graph**, o **DAG**, en lugar de un árbol.  Que el sistema de archivos sea un DAG complica el mantenimiento, pero así es la vida.

[figure4-16]

Compartir archivos es práctico, pero también plantea algunos problemas. Para empezar, si los directorios realmente contienen direcciones de disco, entonces habrá que hacer una copia de las direcciones de disco en el directorio de B cuando se enlace el archivo.  Si posteriormente B o C añaden datos al archivo, los nuevos bloques aparecerán sólo en la dirección del usuario que los añade. Los cambios no serán visibles para el otro usuario, lo que anula el propósito de compartir.

Este problema puede resolverse de dos maneras.  En la primera, los bloques de disco no se listan en directorios, sino en una pequeña estructura de datos asociada al propio archivo. Este es el enfoque utilizado en UNIX (donde la pequeña estructura de datos es el nodo-i).

En la segunda solución, B enlaza con uno de los ficheros de C haciendo que el sistema cree un nuevo fichero, de tipo LINK, e introduciendo dicho fichero en el directorio de B. El nuevo fichero sólo contiene el nombre de la ruta del fichero al que está enlazado.  Cuando B lee del fichero enlazado, el sistema operativo ve que el fichero del que se está leyendo es de tipo LINK, busca el nombre del fichero y lee ese fichero. Este método se denomina **symbolic linking**, en contraste con el enlace tradicional (hard link).


Cada uno de estos métodos tiene sus inconvenientes.  En el primer método, en el momento en que B enlaza con el fichero compartido, el nodo-i registra el propietario del fichero como C. La creación de un enlace no cambia la propiedad (ver Fig. 4-17), pero incrementa el recuento de enlaces en el nodo-i, de forma que el sistema sabe cuántas entradas de directorio apuntan actualmente al fichero.

Si posteriormente C intenta eliminar el archivo, el sistema se enfrenta a un problema: si elimina el archivo y borra el nodo-i, B tendrá una entrada de directorio que apunta a un nodo-i no válido. Si el nodo-i se reasigna posteriormente a otro archivo, el enlace de B apuntará al archivo incorrecto. El sistema puede ver en el recuento del nodo-i que el fichero está todavía en uso, pero no hay una forma fácil de encontrar todas las entradas de directorio del fichero para borrarlas. Los punteros a los directorios no se pueden almacenar en el nodo-i porque puede haber un número ilimitado de directorios.

Lo único que hay que hacer es eliminar la entrada de directorio de C, pero dejar el nodo i intacto, con la cuenta a 1, como se muestra en la Fig. 4-17(c).  Ahora tenemos una situación en la que B es el único usuario que tiene una entrada de directorio para un archivo de propiedad de C. Si el sistema hace contabilidad o tiene cuotas, C continuará siendo facturado por el archivo hasta que B decida eliminarlo, si es que alguna vez lo hace, momento en el que la cuenta pasa a 0 y el archivo es eliminado.

Con los **symbolic links** este problema no se plantea porque sólo el verdadero propietario tiene un puntero al nodo-i. Los usuarios que han enlazado al fichero sólo tienen nombres de ruta, no punteros al nodo-i. Cuando el propietario elimina el archivo, éste se destruye. Los intentos posteriores de utilizar el archivo a través de un enlace simbólico fallarán cuando el sistema no pueda localizar el archivo. La eliminación de un enlace simbólico no afecta al archivo en absoluto.

El problema de los enlaces simbólicos es la sobrecarga adicional que requieren. Hay que leer el archivo que contiene la ruta, analizarla y seguirla, componente a componente, hasta llegar al nodo i. Toda esta actividad puede requerir un número considerable de accesos adicionales al disco. Además, se necesita un nodo-i adicional para cada enlace simbólico, así como un bloque de disco adicional para almacenar la ruta, aunque si el nombre de la ruta es corto, el sistema podría almacenarlo en el propio nodo-i, como una especie de optimización. Los enlaces simbólicos tienen la ventaja de que se pueden utilizar para enlazar a ficheros en máquinas de cualquier parte del mundo, simplemente proporcionando la dirección de red de la máquina donde reside el fichero además de su ruta en esa máquina.

Existe también otro problema introducido por los enlaces, simbólicos o no. Cuando se permiten los enlaces, los archivos pueden tener dos o más rutas. Los programas que comienzan en un directorio determinado y buscan todos los archivos en ese directorio y sus subdirectorios ubicarán un archivo enlazado varias veces. Por ejemplo, un programa que descarga todos los ficheros de un directorio y sus subdirectorios en una cinta puede hacer varias copias de un fichero enlazado. Además, si la cinta se lee en otra máquina, a menos que el programa de descarga sea inteligente, el archivo vinculado se copiará dos veces en el disco, en lugar de ser vinculado.

## 4.3.5 Log-Structured File Systems

Los cambios tecnológicos están ejerciendo presión sobre los file system actuales. En concreto, las CPU son cada vez más rápidas, los discos son cada vez más grandes y baratos (pero no mucho más rápidos) y el tamaño de las memorias crece exponencialmente. El único parámetro que no está mejorando a pasos agigantados es el tiempo de búsqueda del disco (excepto en el caso de los discos de estado sólido, que no tienen tiempo de búsqueda).

La combinación de estos factores significa que se está produciendo un cuello de botella en el rendimiento de muchos sistemas de archivos. Las investigaciones realizadas en Berkeley intentaron paliar este problema diseñando un tipo de sistema de archivos completamente nuevo, el **LFS (Log-structured File System)**.  En esta sección describiremos brevemente cómo funciona LFS. Para un tratamiento más completo, véase el artículo original sobre LFS (Rosenblum y Ouster-hout, 1991).

La idea que impulsó el diseño del LFS es que, a medida que las CPU se hacen más rápidas y las memorias RAM más grandes, las cachés de disco también aumentan rápidamente. En consecuencia, ahora es posible satisfacer una fracción muy importante de todas las peticiones de lectura directamente desde la caché del sistema de archivos, sin necesidad de acceder al disco. De esta observación se deduce que, en el futuro, la mayoría de los accesos al disco serán escrituras, por lo que el mecanismo de lectura anticipada utilizado en algunos sistemas de archivos para recuperar bloques antes de que se necesiten ya no ofrece un gran rendimiento.

Para empeorar las cosas, en la mayoría de los sistemas de archivos, las escrituras se realizan en trozos muy pequeños. Las escrituras pequeñas son muy ineficientes, ya que una escritura en disco de 50-μseg suele ser precedida por una búsqueda de 10-mseg y un retardo rotacional de 4mseg. Con estos parámetros, la eficiencia del disco cae a una fracción del 1%.

Para ver de dónde vienen todas las pequeñas escrituras, considere la creación de un nuevo archivo en un sistema UNIX. Para escribir este archivo, el nodo-i del directorio, el bloque del directorio, el nodo-i del archivo y el propio archivo deben escribirse. Si bien estas escrituras pueden retrasarse, hacerlo expone al sistema de archivos a serios problemas de consistencia si se produce un bloqueo antes de que se realicen las escrituras. Por esta razón, las escrituras del i-nodo se realizan generalmente de forma inmediata.

A partir de este razonamiento, los diseñadores de LFS decidieron reimplementar el sistema de archivos UNIX de forma que se pudiera aprovechar todo el ancho de banda del disco, incluso ante una carga de trabajo compuesta en gran parte por pequeñas escrituras aleatorias. La idea básica es estructurar todo el disco como un gran registro.

Periódicamente, y cuando existe una necesidad especial para ello, todas las escrituras pendientes que se almacenan en memoria se recogen en un único segmento y se escriben en el disco como un único segmento contiguo al final del registro. Así, un único segmento puede contener nodos-i, bloques de directorio y bloques de datos, todos mezclados. Al principio de cada segmento hay un resumen del segmento, que indica lo que se puede encontrar en el segmento.  Si el segmento medio es de aproximadamente 1 MB, se puede utilizar casi todo el ancho de banda del disco.

En este diseño, los nodos-i siguen existiendo e incluso tienen la misma estructura que en UNIX, pero ahora están dispersos por todo el registro, en lugar de estar en una posición fija en el disco. No obstante, cuando se localiza un nodo-i, la localización de los bloques se realiza de la forma habitual. Por supuesto, encontrar un nodo-i es ahora mucho más difícil, ya que su dirección no puede calcularse simplemente a partir de su número-i, como en UNIX.  Para que sea posible encontrar los nodos-i, se mantiene un mapa de nodos-i, indexado por el número-i. La entrada i de este mapa apunta al nodo i del disco. El mapa se guarda en disco, pero también se almacena en caché, por lo que las partes más utilizadas estarán en memoria la mayor parte del tiempo.

Para resumir lo que hemos dicho hasta ahora, todas las escrituras se almacenan inicialmente en memoria, y periódicamente todas las escrituras almacenadas se escriben en el disco en un único segmento, al final del registro. Abrir un fichero consiste ahora en utilizar el mapa para localizar el nodo-i del fichero.  Una vez localizado el nodo-i, las direcciones de los bloques se pueden encontrar a partir de él. Todos los bloques estarán a su vez en segmentos, en algún lugar del log(registro).

Si los discos fueran infinitamente grandes, la descripción anterior sería la historia completa. Sin embargo, los discos reales son finitos, por lo que eventualmente el registro ocupará todo el disco, momento en el cual no se podrán escribir nuevos segmentos en el registro. Afortunadamente, muchos segmentos existentes pueden tener bloques que ya no son necesarios. Por ejemplo, si un archivo se sobrescribe, su nodo i apuntará ahora a los nuevos bloques, pero los antiguos seguirán ocupando espacio en los segmentos escritos anteriormente.

Para hacer frente a este problema, LFS dispone de un hilo **cleaner** que dedica su tiempo a escanear circularmente el registro para compactarlo. Empieza leyendo el resumen del primer segmento del registro para ver qué nodos-i y qué archivos hay. A continuación, comprueba el mapa actual de nodos-i para ver si los nodos-i siguen estando activos y los bloques de archivos siguen en uso.  Si no es así, se descarta esa información. Los nodos-i y los bloques que aún están en uso pasan a la memoria para ser escritos en el siguiente segmento. A continuación, el segmento original se marca como libre, para que el registro pueda utilizarlo para nuevos datos.  De esta manera, el limpiador se mueve a lo largo del registro, eliminando los segmentos antiguos de la parte posterior y poniendo cualquier dato vivo en memoria para reescribirlo en el siguiente segmento. En consecuencia, el disco es un gran buffer circular, con el hilo escritor añadiendo nuevos segmentos en la parte delantera y el hilo limpiador eliminando los antiguos de la parte trasera.

La contabilidad aquí no es trivial, ya que cuando un bloque de archivo se escribe de nuevo en un nuevo segmento, el nodo-i del archivo (en algún lugar del registro) debe ser localizado, actualizado y puesto en memoria para ser escrito en el siguiente segmento.  El mapa del nodo-i debe entonces actualizarse para apuntar a la nueva copia.  No obstante, es posible realizar la administración, y los resultados de rendimiento demuestran que toda esta complejidad merece la pena. Las mediciones realizadas en los documentos citados anteriormente muestran que LFS supera a UNIX en un orden de magnitud en escrituras pequeñas, mientras que su rendimiento es tan bueno o mejor que UNIX en lecturas y escrituras grandes.

## 4.3.6 Journaling File Systems

Aunque los sistemas de archivos con estructura de log son una idea interesante, su uso no está muy extendido, en parte debido a su gran incompatibilidad con los sistemas de archivos existentes. Sin embargo, una de las ideas inherentes a ellos, la robustez ante fallos, puede aplicarse fácilmente a los sistemas de archivos más convencionales. La idea básica es mantener un registro de lo que el sistema de archivos va a hacer antes de que lo haga, de modo que si el sistema se bloquea antes de que pueda hacer el trabajo planeado, al reiniciar el sistema puede mirar el registro para ver lo que estaba pasando en el momento del bloqueo y terminar el trabajo. Este tipo de sistemas de archivos, denominados sistemas de **journaling file systems**, están actualmente en uso. El sistema de archivos NTFS de Microsoft y los sistemas de archivos ext3 y ReiserFS de Linux utilizan journaling. OS X ofrece sistemas de archivos de registro por diario como opción. A continuación haremos una breve introducción a este tema.

Para ver la naturaleza del problema, considere una simple operación común y corriente que ocurre todo el tiempo: eliminar un archivo. Esta operación (en UNIX) requiere tres pasos.

1. Remover el archivo del directorio.
2. Liberar el nodo-i al pool de nodos-i libres.
3. Devolver todos los bloques de disco al pool de bloques de disco libres.

En Windows se requieren pasos análogos. En ausencia de caídas del sistema, el orden en que se realizan estos pasos no importa; en presencia de caídas, sí. Supongamos que se completa el primer paso y, a continuación, el sistema se bloquea. El nodo-i y los bloques de archivo no serán accesibles desde ningún archivo, pero tampoco estarán disponibles para reasignación; estarán en el limbo en algún lugar, disminuyendo los recursos disponibles. Si el fallo se produce después del segundo paso, sólo se pierden los bloques.

Si se cambia el orden de las operaciones y el nodo-i se libera primero, después de reiniciar, el nodo-i puede ser reasignado, pero la antigua entrada de directorio seguirá apuntando a él, por lo tanto al archivo equivocado.  Si los bloques se liberan primero, entonces un fallo antes de que el nodo-i se borre significará que una entrada de directorio válida apunta a un nodo-i que lista bloques ahora en la reserva de almacenamiento libre y que probablemente se reutilizarán en breve, lo que llevará a que dos o más archivos compartan aleatoriamente los mismos bloques. Ninguno de estos resultados es bueno.

Lo que hace el journaling file system es escribir primero una entrada de registro que enumera las tres acciones que deben completarse. A continuación, la entrada de registro se escribe en el disco (y, por si acaso, se lee de nuevo desde el disco para verificar que, de hecho, se ha escrito correctamente).  Sólo después de que se haya escrito la entrada de registro, comienzan las distintas operaciones. Una vez que las operaciones se completan con éxito, la entrada de registro se borra. Si el sistema se bloquea, al recuperarse el file system puede comprobar el registro para ver si había alguna operación pendiente. Si es así, todas ellas pueden volver a ejecutarse (varias veces en caso de caídas repetidas) hasta que el archivo se elimine correctamente.

Para que el journaling funcione, las operaciones registradas deben ser **idempotent**, lo que significa que pueden repetirse tantas veces como sea necesario sin sufrir daños. Operaciones como ''Actualizar el mapa de bits para marcar el nodo i k o el bloque n como libres'' pueden repetirse hasta que las vacas vuelvan a casa sin peligro. Del mismo modo, buscar en un directorio y eliminar cualquier entrada llamada foobar también es idempotente. Por otro lado, añadir los bloques recién liberados del nodo-i K al final de la lista de libres no es idempotente, ya que puede que ya estén ahí. La operación más cara ''Buscar en la lista de bloques libres y añadir el bloque n a ella si no está ya presente'' es idempotente. Los sistemas de archivos con registro tienen que organizar sus estructuras de datos y operaciones registrables para que todas sean idempotentes. En estas condiciones, la recuperación de fallos puede ser rápida y segura.

Para una mayor fiabilidad, un sistema de ficheros puede introducir el concepto de base de datos de **atomic transaction**. Cuando se utiliza este concepto, un grupo de acciones puede estar entre corchetes mediante las operaciones de inicio de transacción y fin de transacción. . El sistema de archivos sabe entonces que debe completar todas las operaciones entre corchetes o ninguna de ellas, pero ninguna otra combinación.

NTFS dispone de un extenso sistema de registro y su estructura rara vez se daña por fallos del sistema. Ha estado en desarrollo desde su primer lanzamiento con WindowsNT en 1993. El primer sistema de archivos de Linux en hacer journaling fue ReiserFS, pero su popularidad se vio obstaculizada por el hecho de que era incompatible con el entonces sistema de archivos estándar ext2. En cambio, ext3, que es un proyecto menos ambicioso que ReiserFS, también hace journaling manteniendo la compatibilidad con el sistema ext2 anterior.

## 4.3.7 Virtual File Systems

En un mismo ordenador se utilizan muchos sistemas de archivos diferentes, incluso para el mismo sistema operativo. Un sistema Windows puede tener un sistema de archivos NTFS principal, pero también una unidad o partición FAT-32 o FAT-16 heredada que contenga datos antiguos, pero aún necesarios, y de vez en cuando también puede necesitarse una unidad flash, un CD-ROM antiguo o un DVD (cada uno con su propio sistema de archivos). Windows gestiona estos sistemas de archivos dispares identificando cada uno con una letra de unidad diferente, como C:, D:, etc. Cuando un proceso abre un archivo, la letra de la unidad está explícita o implícitamente presente para que Windows sepa a qué sistema de archivos debe pasar la solicitud. No hay ningún intento de integrar sistemas de archivos heterogéneos en un todo unificado.

Por el contrario, todos los sistemas UNIX modernos intentan seriamente integrar múltiples sistemas de archivos en una única estructura. Un sistema Linux podría tener ext2 como sistema de archivos raíz, con una partición ext3 montada en /usr y un segundo disco duro con un sistema de archivos ReiserFS montado en /home, así como un CD-ROM ISO 9660 montado temporalmente en /mnt. Desde el punto de vista del usuario, existe una única jerarquía de sistemas de archivos. El hecho de que abarque varios sistemas de archivos (incompatibles) no es visible para los usuarios ni para los procesos.

Sin embargo, la presencia de múltiples sistemas de archivos es definitivamente visible para la implementación, y desde el trabajo pionero de Sun Microsystems (Kleiman, 1986), la mayoría de los sistemas UNIX han utilizado el concepto de un **VFS (Virtual File System)** para tratar de integrar múltiples sistemas de archivos en una estructura ordenada. La idea clave es abstraer la parte del sistema de archivos que es común a todos los sistemas de archivos y poner ese código en una capa separada que llama a los sistemas de archivos concretos subyacentes para gestionar realmente los datos. La estructura general se ilustra en la Fig. 4-18.  La estructura que sigue no es específica de Linux o FreeBSD o cualquier otra versión de UNIX, pero da una idea general de cómo funcionan los sistemas de archivos virtuales en los sistemas UNIX.

[figure4-18]

Todas las llamadas del sistema relacionadas con archivos se dirigen al sistema de archivos virtual para su procesamiento inicial. Estas llamadas, procedentes de los procesos de usuario, son las llamadas POSIX estándar, como open, read, write, lseek, etc. Así, el VFS tiene una interfaz "superior" para los procesos de usuario y es la conocida interfaz POSIX.

El VFS también tiene una interfaz "inferior" con los sistemas de archivos concretos, etiquetada como **VFS Interface** en la Fig. 4-18. Esta interfaz consiste en varias docenas de llamadas a funciones que el VFS puede hacer a cada sistema de archivos para realizar su trabajo.  Esta interfaz consiste en varias docenas de llamadas a funciones que el VFS puede hacer a cada sistema de archivos para realizar su trabajo. Por lo tanto, para crear un nuevo sistema de archivos que funcione con el VFS, los diseñadores del nuevo sistema de archivos deben asegurarse de que proporciona las llamadas a funciones que el VFS requiere. Un ejemplo obvio de este tipo de función es la que lee un bloque específico del disco, lo coloca en la caché del búfer del sistema de archivos y devuelve un puntero al mismo. Por tanto, el VFS tiene dos interfaces distintas: la superior para los procesos de usuario y la inferior para los sistemas de archivos concretos.

Aunque la mayoría de los sistemas de archivos del VFS representan particiones de un disco local, no siempre es así. De hecho, la motivación original de Sun para crear el VFS era admitir sistemas de archivos remotos mediante el protocolo **NFS (Network File System)**. El diseño del VFS es tal que, mientras el sistema de archivos concreto proporcione las funciones que el VFS necesita, el VFS no sabe ni le importa dónde se almacenan los datos ni cómo es el sistema de archivos subyacente.

Internamente, la mayoría de las implementaciones de VFS están esencialmente orientadas a objetos, aunque estén escritas en C en lugar de C++. Normalmente se admiten varios tipos de objetos clave. Entre ellos se encuentran el superbloque (que describe un sistema de archivos), el nodo-v (que describe un archivo) y el directorio (que describe un directorio del sistema de archivos). Cada uno de ellos tiene operaciones asociadas (métodos) que los sistemas de archivos concretos deben soportar. Además, el VFS tiene algunas estructuras de datos internas para su propio uso, incluida la tabla de montaje y una matriz de descriptores de archivos para realizar un seguimiento de todos los archivos abiertos en los procesos de usuario.

Para entender cómo funciona el VFS, veamos un ejemplo cronológico. Cuando se arranca el sistema, el sistema de archivos raíz se registra en el VFS. Además, cuando se montan otros sistemas de archivos, ya sea en el arranque o durante la operación, también deben registrarse en el VFS. Cuando un sistema de archivos se registra, lo que hace básicamente es proporcionar una lista de las direcciones de las funciones que requiere el VFS, ya sea como un vector de llamada largo (tabla) o como varios de ellos, uno por objeto VFS, según lo exija el VFS. Así, una vez que un sistema de archivos se ha registrado en el VFS, éste sabe cómo, por ejemplo, leer un bloque de él: simplemente llama a la cuarta función (o la que sea) del vector proporcionado por el sistema de archivos. Del mismo modo, el VFS también sabe cómo llevar a cabo cualquier otra función que el sistema de archivos concreto deba suministrar: simplemente llama a la función cuya dirección se suministró cuando el sistema de archivos se registró.

Después de que un file system ha sido montado, este puede ser usado. Por ejemplo, si un file system ha sido montado en /usr y un proceso realiza la llamada:

```shell
    open("/usr/include/unistd.h", O RDONLY)
```

mientras analiza la ruta, el VFS ve que se ha montado un nuevo sistema de archivos en /usr y localiza su superbloque buscando en la lista de superbloques de sistemas de archivos montados. Una vez hecho esto, puede encontrar el directorio raíz del sistema de archivos montado y buscar la ruta include/unistd.h allí. A continuación, el VFS crea un nodo V y realiza una llamada al sistema de archivos concreto para devolver toda la información del nodo i del archivo. Esta información se copia en el nodo-v (en RAM), junto con otra información, la más importante el puntero a la tabla de funciones a llamar para operaciones en los nodos-v, como leer, escribir, cerrar, etc.

Una vez creado el nodo V, el VFS crea una entrada en la tabla de descriptores de archivo para el proceso que llama y la configura para que apunte al nuevo nodo v. (Para los puristas, en realidad apunta a otra estructura de datos que contiene la posición actual del archivo y un puntero al nodo V). Por último, el VFS devuelve el descriptor de archivo a la persona que llama para que pueda utilizarlo para leer, escribir y cerrar el archivo.

Más tarde, cuando el proceso hace aread utilizando el descriptor de archivo, el VFS localiza el nodo v desde las tablas de procesos y de descriptores de archivo y sigue el puntero a la tabla de funciones, todas las cuales son direcciones dentro del sistema de archivos concreto en el que reside el archivo solicitado. Ahora se llama a la función que gestiona la lectura y el código del sistema de archivos concreto va y obtiene el bloque solicitado. El VFS no tiene ni idea de si los datos proceden del disco local, de un sistema de archivos remoto a través de la red, de una memoria USB o de algo diferente. Las estructuras de datos involucradas se muestran en la Fig. 4-19.  Empezando por el número de proceso del llamante y el descriptor de fichero, se localizan sucesivamente el nodo-v, el puntero de la función de lectura y la función de acceso dentro del sistema de ficheros concreto.

![figure4-19](https://github.com/gabo52/SistemasOperativos/blob/main/figures/Chapter4/figure4-19.png?raw=true)

De este modo, resulta relativamente sencillo añadir nuevos sistemas de archivos. Para crear uno, los diseñadores obtienen primero una lista de las llamadas a funciones que espera el VFS y, a continuación, escriben su sistema de archivos para proporcionarlas todas. Alternativamente, si el sistema de archivos ya existe, entonces tienen que proporcionar funciones envolventes que hagan lo que el VFS necesita, normalmente haciendo una o más llamadas nativas al sistema de archivos concreto.



####
El autor en la página 295 muestra un caso donde se realiza un hard link por parte de 2 usuarios a un mismo archivo(por ende a un mismo i-nodo). El autor indica que tenemos un propietario C y un usuario B que tiene el i-nodo de un archivo perteneciente a C(por ende el count del i-node es 2). El autor dice que que si C borra el archivo, (cuyo count de i-node pasaría a ser 1), y luego se reasigna el i-nodo a otro archivo, B podría estar apuntando a otro archivo pues el i-nodo fue reasignado. 

Esto es contradictorio puesto que no es posible que un i-nodo pueda ser liberado o reasignado a menos que su count sea 0, y en este caso al C borrar el archivo solo disminuye su count del i-node pasándolo a 1.

En mi opinión, y por lo sustentado, el autor se ha equvicoado o presenta ambiguedad al mostrar este caso pues contradice la funcionalidad del i-nodo en UNIX. ¿Estoy en lo correcto?

Preguntas:

Explica la imagen 4.9

Qué es el algoritmo continue locating?
Que pros tiene?
Que contras?


¿Qué es el contiguos allocation?
¿Cómo funciona una linked-list sin table?
¿Cómo funciona una linked-list con table?
¿Cómo funciona un i-nodo?
¿Qué limitación tienen y cómo se soluciona?
¿Cuál es mejor en términos de memoria?
¿Cómo se pueden guardar los atributos de un directory?
Explica el problema de fallos de página en archivos con nombre largo.

Explica esto:
En cualquier caso, se comprueba la entrada de la tabla correspondiente al código hash. Si no se utiliza, se coloca un puntero a la entrada del archivo. Si esa ranura ya está en uso, se construye una lista enlazada, encabezada por la entrada de la tabla y recorriendo todas las entradas con el mismo valor hash.

Explica las soluciones de los nombres de archivos largo.
Explica como se mapea un directorio y archivo con una tabla hash.
Explica la solución a los ficheros compartidos.

¿Cómo funciona un backlog?

¿Cómo funciona un journaling file system?
¿Qué ideas toma?

¿Cómo funciona ante fallos?
¿Cómo deben ser sus operaciones?

Cuales son las 3 operaciones que toma la función remove en unix?

Dibuje un i-nodo

¿Cómo deben ser las operaciones del journaling system?

¿Cómo maneja Windows los distintos sistemas de archivos que tiene?

¿Cómo funcionan los VFS?
¿Pueden también adaptarse para red?
¿Qué es el superbloque, el v node y el directory en VFS?
Como funciona esto al usar 

open("/usr/include/unistd.h", O RDONLY)